{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"trofi-x_xlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852655455,"user_tz":-120,"elapsed":336,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b95f6d83-25db-4d91-dfd7-fbafce99ea37"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852658088,"user_tz":-120,"elapsed":2221,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"677824e7-0149-47e7-9015-90c2f31b8301"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852658537,"user_tz":-120,"elapsed":455,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"568b8c7a-8def-4466-86ac-e2f7afdf9704"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L"},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852661242,"user_tz":-120,"elapsed":2710,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"06d38afe-ad59-4b9c-818e-fd7c8900f66e"},"source":["!pip install transformers==3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.95)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1623852661246,"user_tz":-120,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c2760231-c0f9-425d-becf-4788ac59c008"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB"},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"data/trofix.csv\")\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"arg1\", \"arg2\", \"verb\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"ok","timestamp":1623852661263,"user_tz":-120,"elapsed":44,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ac3c0e27-0e67-4656-b6b5-9c9566b0af9e"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"data/trofix.csv\")\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of training sentences: 1,444\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>sentence</th>\n","      <th>verb_stem</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>mileage</td>\n","      <td>struck</td>\n","      <td>blow</td>\n","      <td>Triple mileage has struck another blow to the ...</td>\n","      <td>strike</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>terrorist</td>\n","      <td>attack</td>\n","      <td>target</td>\n","      <td>U.S. officials said evidence suggests that a J...</td>\n","      <td>attack</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>forces</td>\n","      <td>stepped</td>\n","      <td>use</td>\n","      <td>Some police forces , for example , have steppe...</td>\n","      <td>step</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>day</td>\n","      <td>pour</td>\n","      <td>stream</td>\n","      <td>Every day his troops gather under the green , ...</td>\n","      <td>pour</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>manufacturers</td>\n","      <td>rolling</td>\n","      <td>products</td>\n","      <td>He says manufacturers are increasingly rolling...</td>\n","      <td>roll</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            arg1     arg2  ... verb_stem label\n","0        mileage   struck  ...    strike     1\n","1      terrorist   attack  ...    attack     0\n","2         forces  stepped  ...      step     0\n","3            day     pour  ...      pour     0\n","4  manufacturers  rolling  ...      roll     1\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1"},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852661266,"user_tz":-120,"elapsed":39,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b2856604-69a2-453e-d6ac-958eda129acb"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values\n","labels = df.label.values\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 1, 1])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1623852663787,"user_tz":-120,"elapsed":2555,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"5513a8f5-bf2c-4a05-f677-e3959c995f05"},"source":["!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852664670,"user_tz":-120,"elapsed":889,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"39699277-eafd-47b7-cb89-81b129839317"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852664672,"user_tz":-120,"elapsed":11,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"f89f1706-1e01-4935-d340-fcd67d4f71e2"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  Triple mileage has struck another blow to the coupon market .\n","Tokenized:  ['▁triple', '▁mile', 'age', '▁has', '▁s', 'truck', '▁another', '▁blow', '▁to', '▁the', '▁coup', 'on', '▁market', '▁', '.']\n","Token IDs:  [162738, 84765, 4588, 1556, 91, 173964, 15700, 102310, 47, 70, 14974, 191, 16839, 6, 5]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1623852665141,"user_tz":-120,"elapsed":475,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"eed89c7b-4b21-4e7f-d6ce-f2fa6c740a36"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  Triple mileage has struck another blow to the coupon market .\n","Token IDs: tensor([     0, 162738,  84765,   4588,   1556,     91, 173964,  15700, 102310,\n","            47,     70,  14974,    191,  16839,      6,      5,      2,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([1, 0, 0,  ..., 0, 1, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1623852665142,"user_tz":-120,"elapsed":10,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ca6643e3-44fc-43a8-eb36-4c5cb257324e"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1,299 training samples\n","  145 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk"},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1623852683772,"user_tz":-120,"elapsed":18144,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"d5dcf2b3-d774-4c62-f006-fac841061f8f"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1623852683774,"user_tz":-120,"elapsed":29,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e8657b81-d7d7-4deb-90ef-f9b28196b53a"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv"},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1623852784891,"user_tz":-120,"elapsed":101139,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"d3f69724-a2c4-4033-8000-c7f2830a9381"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.70\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.59\n","  Validation Loss: 0.67\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.67\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.61\n","  Validation Loss: 0.65\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation Loss: 0.63\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.58\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.65\n","  Validation Loss: 0.68\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.48\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation Loss: 0.64\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.39\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.68\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.33\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation Loss: 0.75\n","  Validation took: 0:00:00\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.65\n","  Validation took: 0:00:00\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.78\n","  Validation took: 0:00:00\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of     41.    Elapsed: 0:00:10.\n","torch.Size([19, 128])\n","torch.Size([19, 128])\n","torch.Size([19])\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:00:10\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.76\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Total training took 0:01:41 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1623852784894,"user_tz":-120,"elapsed":22,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"0e626cfa-ce02-4fe2-988d-b3469d145d3f"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.70</td>\n","      <td>0.67</td>\n","      <td>0.59</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.67</td>\n","      <td>0.65</td>\n","      <td>0.61</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.63</td>\n","      <td>0.63</td>\n","      <td>0.67</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.58</td>\n","      <td>0.68</td>\n","      <td>0.65</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.48</td>\n","      <td>0.64</td>\n","      <td>0.66</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.39</td>\n","      <td>0.68</td>\n","      <td>0.72</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.33</td>\n","      <td>0.75</td>\n","      <td>0.68</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.26</td>\n","      <td>0.65</td>\n","      <td>0.76</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.22</td>\n","      <td>0.78</td>\n","      <td>0.75</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.19</td>\n","      <td>0.76</td>\n","      <td>0.73</td>\n","      <td>0:00:10</td>\n","      <td>0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.70         0.67           0.59       0:00:10         0:00:00\n","2               0.67         0.65           0.61       0:00:10         0:00:00\n","3               0.63         0.63           0.67       0:00:10         0:00:00\n","4               0.58         0.68           0.65       0:00:10         0:00:00\n","5               0.48         0.64           0.66       0:00:10         0:00:00\n","6               0.39         0.68           0.72       0:00:10         0:00:00\n","7               0.33         0.75           0.68       0:00:10         0:00:00\n","8               0.26         0.65           0.76       0:00:10         0:00:00\n","9               0.22         0.78           0.75       0:00:10         0:00:00\n","10              0.19         0.76           0.73       0:00:10         0:00:00"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1623852785577,"user_tz":-120,"elapsed":703,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"fcf2285f-bccc-45dc-a48a-4ff0f46638d5"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852785580,"user_tz":-120,"elapsed":19,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c2d71c68-fc2a-41b3-9993-d3481ba7e1de"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","#test_df = pd.read_csv(\"Datasets/es_lcc_new.csv\")\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of test sentences: 1,444\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg"},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dmz1QpXteUp"},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K"},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['arg1'] = test_df['arg1']\n","my_submission['arg2'] = test_df['arg2']\n","my_submission[\"verb\"] = test_df['verb']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh"},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc"},"source":["my_submission['label'] = final_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W"},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1623852786206,"user_tz":-120,"elapsed":61,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"908817a6-35af-4c31-ae5a-1eb7d9f7cc7d"},"source":["my_submission.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>413</th>\n","      <td>When she hears that prisoners sometimes carve ...</td>\n","      <td>she</td>\n","      <td>grabs</td>\n","      <td>child</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>Morty Bennett eats a scallop and shrimp entree...</td>\n","      <td>bennett</td>\n","      <td>eats</td>\n","      <td>scallop</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1034</th>\n","      <td>The latest truce in the week-old battle , whic...</td>\n","      <td>which</td>\n","      <td>killed</td>\n","      <td>188</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>All agree that the state must diversify its in...</td>\n","      <td>state</td>\n","      <td>escape</td>\n","      <td>base</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1024</th>\n","      <td>`` It floods the area instead of having hot pi...</td>\n","      <td>it</td>\n","      <td>floods</td>\n","      <td>area</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence  ... label\n","413   When she hears that prisoners sometimes carve ...  ...     1\n","316   Morty Bennett eats a scallop and shrimp entree...  ...     0\n","1034  The latest truce in the week-old battle , whic...  ...     0\n","65    All agree that the state must diversify its in...  ...     1\n","1024  `` It floods the area instead of having hot pi...  ...     0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852786208,"user_tz":-120,"elapsed":62,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"629f66dd-e30b-4295-fe77-09d4cccff29d"},"source":["my_submission.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 6)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852786209,"user_tz":-120,"elapsed":56,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"5eec6238-2b67-49cb-b91b-6ebee1b1bbe1"},"source":["test_df.label.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    80\n","1    65\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"nTtwGl9vxOoG"},"source":["final = my_submission[(my_submission['correct_label'] == my_submission['label'])]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iVw1NZ2xO0C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852786212,"user_tz":-120,"elapsed":53,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"caa01077-3358-4ee5-f668-b292e43cb025"},"source":["final.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(137, 6)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n"},"source":["final_met = my_submission[(my_submission['correct_label'] == 1) & (my_submission['label'] ==1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852786214,"user_tz":-120,"elapsed":50,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"bf0753c7-84a8-487b-9655-1bdbeb91bc5c"},"source":["final_met.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60, 6)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"RFTH_BCexeY1"},"source":["final_lit = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEwct9X5xehQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852786217,"user_tz":-120,"elapsed":46,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2332d52a-beb3-4d43-ed37-d9d7a6fd66f1"},"source":["final_lit.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(77, 6)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"Rs-f8IKraTz5"},"source":["#print(logits)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7"},"source":["my_submission.to_csv('trofi_sub.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GYFtiTEk7MP"},"source":["#final_met.to_csv(\"final_met.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Whz6mWvpidb-"},"source":["#Save and load fine-tuned model"]},{"cell_type":"code","metadata":{"id":"73UumM0PhBym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852789526,"user_tz":-120,"elapsed":3347,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"33562bf9-1c67-49be-d89e-d32428ae7fb8"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'trofix_xlmroberta/xlm-roberta_model_save'\n","# output_dir = './content/xlm-roberta_model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to trofix_xlmroberta/xlm-roberta_model_save\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('trofix_xlmroberta/xlm-roberta_model_save/sentencepiece.bpe.model',\n"," 'trofix_xlmroberta/xlm-roberta_model_save/special_tokens_map.json',\n"," 'trofix_xlmroberta/xlm-roberta_model_save/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"LmN96FOqjLKd"},"source":["#Import saved model and test"]},{"cell_type":"code","metadata":{"id":"ScJHWcE5hB4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852792313,"user_tz":-120,"elapsed":2802,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"166331ca-dd5a-4cbc-c48f-05dc432b3a1d"},"source":["!pip install transformers\n","\n","from transformers import XLMRobertaForSequenceClassification\n","\n","output_dir = 'trofix_xlmroberta/xlm-roberta_model_save'\n","\n","print(output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.95)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","trofix_xlmroberta/xlm-roberta_model_save\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SZbux55ucvy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623852808691,"user_tz":-120,"elapsed":16386,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e212a8b8-2997-4029-aebb-e9c126945037"},"source":["from transformers import XLMRobertaTokenizer\n","import torch\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n","model_loaded = XLMRobertaForSequenceClassification.from_pretrained(output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lhw_GFdIuwR4"},"source":[""],"execution_count":null,"outputs":[]}]}