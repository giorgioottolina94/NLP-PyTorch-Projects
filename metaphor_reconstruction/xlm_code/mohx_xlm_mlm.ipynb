{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"mohx_xlm_mlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784758046,"user_tz":-120,"elapsed":420,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e7daaf5d-eebf-4eba-ef3f-73e96b87552d"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784760489,"user_tz":-120,"elapsed":2449,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"00ee2fd3-38b4-4571-bd2e-91540c7836e5"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784761095,"user_tz":-120,"elapsed":612,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b4c5046d-19f2-4c4a-8dd4-6cdb170293bd"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L"},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784764372,"user_tz":-120,"elapsed":3282,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"3cf59471-e7e6-46d5-dba6-2341e66150da"},"source":["!pip install transformers==3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.95)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1623784764373,"user_tz":-120,"elapsed":20,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e6daa087-ea18-4ee5-8e6a-6f8c97d6b8b2"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB"},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"data/mohx_xlm_mlm.csv\")\n","\n","data = data.fillna(0)\n","data['label'] = data['label'].astype(int)\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"m8YlVFajHCA4","executionInfo":{"status":"ok","timestamp":1623784764376,"user_tz":-120,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"512eb1fe-4826-40fa-afc6-df0cc8e367db"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>sentence</th>\n","      <th>verb_idx</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>knowledge</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>He absorbed the knowledge or beliefs of his tr...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cost</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>He absorbed the costs for the accident .</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tax</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>The sales revenue is incorporated into the sta...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>immigrant</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>The immigrants were quickly absorbed into soci...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>interest</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>Her interest in butterflies absorbs her comple...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        arg1  arg2  ... verb_idx label\n","0  knowledge   0.0  ...        1     1\n","1       cost   0.0  ...        1     1\n","2        tax   0.0  ...        4     1\n","3  immigrant   0.0  ...        4     1\n","4   interest   0.0  ...        4     1\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1623784764864,"user_tz":-120,"elapsed":499,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c48f76ab-e8ac-4490-cb6d-ac77fa5e27a8"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"data/mohx_xlm_mlm.csv\")\n","\n","df = df.fillna(0)\n","df['label'] = df['label'].astype(int)\n","\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of training sentences: 647\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>arg1</th>\n","      <th>arg2</th>\n","      <th>verb</th>\n","      <th>sentence</th>\n","      <th>verb_idx</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>knowledge</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>He absorbed the knowledge or beliefs of his tr...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cost</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>He absorbed the costs for the accident .</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tax</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>The sales revenue is incorporated into the sta...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>immigrant</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>The immigrants were quickly absorbed into soci...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>interest</td>\n","      <td>0.0</td>\n","      <td>absorb</td>\n","      <td>Her interest in butterflies absorbs her comple...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        arg1  arg2  ... verb_idx label\n","0  knowledge   0.0  ...        1     1\n","1       cost   0.0  ...        1     1\n","2        tax   0.0  ...        4     1\n","3  immigrant   0.0  ...        4     1\n","4   interest   0.0  ...        4     1\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1"},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784764867,"user_tz":-120,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"18ae627f-dc09-46e4-dfd8-2fbd494018a6"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values\n","labels = df.label.values\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n","       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n","       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n","       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n","       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n","       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n","       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n","       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n","       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n","       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n","       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n","       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n","       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n","       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n","       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n","       1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n","       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n","       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n","       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n","       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n","       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n","       0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n","       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n","       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n","       0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n","       0, 0, 0, 1, 0, 0, 1, 0, 0])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1623784768044,"user_tz":-120,"elapsed":3187,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"80a6e2f4-62df-42cd-a6dd-32beb28b392a"},"source":["!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784769650,"user_tz":-120,"elapsed":1629,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2bc24775-9d60-4b52-b2fd-c00145bd0e4f"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784769652,"user_tz":-120,"elapsed":43,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2a39cd35-4108-4ea6-ca9b-89b8a853102e"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  He absorbed the knowledge or beliefs of his tribe .\n","Tokenized:  ['▁he', '▁absorb', 'ed', '▁the', '▁knowledge', '▁or', '▁belief', 's', '▁of', '▁his', '▁tri', 'be', '▁', '.']\n","Token IDs:  [764, 57622, 297, 70, 51359, 707, 144239, 7, 111, 1919, 1927, 372, 6, 5]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1623784769653,"user_tz":-120,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"3599221e-3823-4be6-9bef-67262ce0951f"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  He absorbed the knowledge or beliefs of his tribe .\n","Token IDs: tensor([     0,    764,  57622,    297,     70,  51359,    707, 144239,      7,\n","           111,   1919,   1927,    372,      6,      5,      2,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n","        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","        0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n","        1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n","        1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n","        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n","        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n","        0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n","        1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n","        1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n","        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n","        0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n","        0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n","        1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n","        1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n","        0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n","        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n","        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n","        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","        1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n","        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n","        1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1623784769654,"user_tz":-120,"elapsed":23,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b87c18a5-fb1a-4311-d726-59581e43e704"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  582 training samples\n","   65 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk"},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1623784793186,"user_tz":-120,"elapsed":23544,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"02817f64-fdc5-47f0-f655-82df025f4f1f"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1623784793187,"user_tz":-120,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"828a2f70-0e9c-4d4f-a76f-4c2747395c66"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv"},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1623784872240,"user_tz":-120,"elapsed":79079,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c988ce4a-abf8-4957-caa6-d976403eec05"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.70\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.68\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.68\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.49\n","  Validation Loss: 0.59\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.59\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.86\n","  Validation Loss: 0.50\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.51\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.84\n","  Validation Loss: 0.37\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.45\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.91\n","  Validation Loss: 0.49\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.41\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.52\n","  Validation Loss: 0.97\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.37\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.88\n","  Validation Loss: 0.31\n","  Validation took: 0:00:00\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.32\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.89\n","  Validation Loss: 0.30\n","  Validation took: 0:00:00\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.86\n","  Validation Loss: 0.34\n","  Validation took: 0:00:00\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([6, 128])\n","torch.Size([6, 128])\n","torch.Size([6])\n","\n","  Average training loss: 0.31\n","  Training epcoh took: 0:00:08\n","\n","Running Validation...\n","  Accuracy: 0.89\n","  Validation Loss: 0.32\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Total training took 0:01:19 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1623784872243,"user_tz":-120,"elapsed":39,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a7c41143-baca-4dcd-812d-c71f11d67d5a"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.70</td>\n","      <td>0.68</td>\n","      <td>0.72</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.68</td>\n","      <td>0.59</td>\n","      <td>0.49</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.59</td>\n","      <td>0.50</td>\n","      <td>0.86</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.51</td>\n","      <td>0.37</td>\n","      <td>0.84</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.45</td>\n","      <td>0.49</td>\n","      <td>0.91</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.41</td>\n","      <td>0.97</td>\n","      <td>0.52</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.37</td>\n","      <td>0.31</td>\n","      <td>0.88</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.32</td>\n","      <td>0.30</td>\n","      <td>0.89</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.30</td>\n","      <td>0.34</td>\n","      <td>0.86</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.31</td>\n","      <td>0.32</td>\n","      <td>0.89</td>\n","      <td>0:00:08</td>\n","      <td>0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.70         0.68           0.72       0:00:08         0:00:00\n","2               0.68         0.59           0.49       0:00:08         0:00:00\n","3               0.59         0.50           0.86       0:00:08         0:00:00\n","4               0.51         0.37           0.84       0:00:08         0:00:00\n","5               0.45         0.49           0.91       0:00:08         0:00:00\n","6               0.41         0.97           0.52       0:00:08         0:00:00\n","7               0.37         0.31           0.88       0:00:08         0:00:00\n","8               0.32         0.30           0.89       0:00:08         0:00:00\n","9               0.30         0.34           0.86       0:00:08         0:00:00\n","10              0.31         0.32           0.89       0:00:08         0:00:00"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1623784873628,"user_tz":-120,"elapsed":1418,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"6aeea00b-02d9-4723-ed34-bbf9c62f1291"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784873630,"user_tz":-120,"elapsed":81,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"82ddf013-2aa7-48d8-fd1d-5b5809ee045c"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","#test_df = pd.read_csv(\"Datasets/es_lcc_new.csv\")\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of test sentences: 647\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg"},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qmj7fm818zxM"},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K"},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh"},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc"},"source":["my_submission['label'] = final_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W"},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"status":"ok","timestamp":1623784873640,"user_tz":-120,"elapsed":77,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"15df5db1-b94f-4020-9133-af52b35c21c9"},"source":["my_submission.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>634</th>\n","      <td>He marched into the classroom and announced th...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>220</th>\n","      <td>The stars gravitate towards each other .</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>A hot drink will comfort me .</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>He created this kind of opera .</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>They found their feet to the top of the mounta...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              sentence  correct_label  label\n","634  He marched into the classroom and announced th...              0      0\n","220           The stars gravitate towards each other .              0      0\n","426                      A hot drink will comfort me .              1      0\n","428                    He created this kind of opera .              1      1\n","72   They found their feet to the top of the mounta...              1      1"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784873642,"user_tz":-120,"elapsed":76,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ef158841-27e0-4265-a23f-1f519bd99e94"},"source":["my_submission.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(65, 3)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784873644,"user_tz":-120,"elapsed":70,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"4046739e-c670-4ece-c910-6f42b5fbcc76"},"source":["test_df.label.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    36\n","0    29\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"nTtwGl9vxOoG"},"source":["final = my_submission[(my_submission['correct_label'] == my_submission['label'])]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iVw1NZ2xO0C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784873647,"user_tz":-120,"elapsed":65,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2552e033-1308-45fc-b348-c96485ef4291"},"source":["final.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(58, 3)"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n"},"source":["final_met = my_submission[(my_submission['correct_label'] == 1) & (my_submission['label'] ==1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784873654,"user_tz":-120,"elapsed":65,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"7f4578f5-9a83-47ce-e4a7-8f71c6cc1648"},"source":["final_met.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(31, 3)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"RFTH_BCexeY1"},"source":["final_lit = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEwct9X5xehQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784873657,"user_tz":-120,"elapsed":62,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c41c03e9-37e1-4d22-c351-0d07e9c58bd2"},"source":["final_lit.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(27, 3)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"Rs-f8IKraTz5"},"source":["#print(logits)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7"},"source":["my_submission.to_csv('mohx_sub.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GYFtiTEk7MP"},"source":["#final_met.to_csv(\"final_met.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Whz6mWvpidb-"},"source":["#Save and load fine-tuned model"]},{"cell_type":"code","metadata":{"id":"73UumM0PhBym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784898177,"user_tz":-120,"elapsed":24572,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"538d143d-f084-49af-9d4a-e16e2116ca65"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'mohx_xlmroberta/xlm-roberta_model_save'\n","# output_dir = './content/xlm-roberta_model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to mohx_xlmroberta/xlm-roberta_model_save\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('mohx_xlmroberta/xlm-roberta_model_save/sentencepiece.bpe.model',\n"," 'mohx_xlmroberta/xlm-roberta_model_save/special_tokens_map.json',\n"," 'mohx_xlmroberta/xlm-roberta_model_save/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"LmN96FOqjLKd"},"source":["#Import saved model and test"]},{"cell_type":"code","metadata":{"id":"ScJHWcE5hB4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784901795,"user_tz":-120,"elapsed":3640,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"7991497f-d5da-40e4-b455-95d9b9818cf8"},"source":["!pip install transformers\n","\n","from transformers import XLMRobertaForSequenceClassification\n","\n","output_dir = 'mohx_xlmroberta/xlm-roberta_model_save'\n","\n","print(output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.95)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","mohx_xlmroberta/xlm-roberta_model_save\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SZbux55ucvy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623784923281,"user_tz":-120,"elapsed":21506,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"88b618b0-6dd6-4d10-e1cc-b3ed58a460d9"},"source":["from transformers import XLMRobertaTokenizer\n","import torch\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n","model_loaded = XLMRobertaForSequenceClassification.from_pretrained(output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer...\n"],"name":"stdout"}]}]}