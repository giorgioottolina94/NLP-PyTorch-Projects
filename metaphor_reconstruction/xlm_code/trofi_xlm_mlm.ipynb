{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"trofi_xlm_mlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"39ae4b96ac9e422aba8cbd840bcc2e99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_64307f381df748bbb8bb4fffe82217d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5d2892d513c644148cccf40ee30a6aec","IPY_MODEL_7fa21fbd5fc845a9a9f43f055756e8f8"]}},"64307f381df748bbb8bb4fffe82217d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d2892d513c644148cccf40ee30a6aec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1c31a4769bb043b78eab3fb54744b294","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2ca171d5904492fb0ea4e2c56096809"}},"7fa21fbd5fc845a9a9f43f055756e8f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c00bdb2cf97447f9b75278feb2dd7a84","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:01&lt;00:00, 3.61MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d48eaeeaef14146980e65c740237db2"}},"1c31a4769bb043b78eab3fb54744b294":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d2ca171d5904492fb0ea4e2c56096809":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c00bdb2cf97447f9b75278feb2dd7a84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6d48eaeeaef14146980e65c740237db2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0508fb7a69ca4bbe8b1a2ced595bc3c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_557affa966944986b1118001551d367b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b6cdb47ae18049f885249218a00ba296","IPY_MODEL_2f61f214e0e64a7181c2a2b5ca9988d8"]}},"557affa966944986b1118001551d367b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6cdb47ae18049f885249218a00ba296":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ef914aad6084fd791c82a25676b84f1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6991f9c42c6645698341f594ef6c7c2f"}},"2f61f214e0e64a7181c2a2b5ca9988d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f284adb3605f472cb31e3a52453f33ac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 512/512 [00:30&lt;00:00, 16.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41a21ce334924d88931e1d77c4adcf9d"}},"4ef914aad6084fd791c82a25676b84f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6991f9c42c6645698341f594ef6c7c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f284adb3605f472cb31e3a52453f33ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"41a21ce334924d88931e1d77c4adcf9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbf1b9ad3adf40198b54b8897253edbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b1bd37d0e02e4d23b1495e800df74f44","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_641fdf7d00484320ada0e201fb6556b7","IPY_MODEL_13b92641239b4c0e93480c6a0823971d"]}},"b1bd37d0e02e4d23b1495e800df74f44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"641fdf7d00484320ada0e201fb6556b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_898fff106eee4e6fb01391ad66ba25dc","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1115590446,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1115590446,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eaea88fc232846e480b72b0395deb69e"}},"13b92641239b4c0e93480c6a0823971d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1ef91824cbc2483bbb4850632aefcb86","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.12G/1.12G [00:30&lt;00:00, 36.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a2f8a2451444fd5a7397d842149093b"}},"898fff106eee4e6fb01391ad66ba25dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eaea88fc232846e480b72b0395deb69e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ef91824cbc2483bbb4850632aefcb86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3a2f8a2451444fd5a7397d842149093b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623791719552,"user_tz":-120,"elapsed":18653,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"77d88f6c-b218-4ae8-a392-b4fd58fa6657"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623791724265,"user_tz":-120,"elapsed":4727,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"51078f54-32d3-4cbe-df3a-8b6d8ff88069"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623791726092,"user_tz":-120,"elapsed":1836,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9e44399c-733f-40b0-d766-0f5792c9717c"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L","executionInfo":{"status":"ok","timestamp":1623791726093,"user_tz":-120,"elapsed":7,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623791732542,"user_tz":-120,"elapsed":6455,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"353228f6-1184-4cab-dbf4-b87c26a1d6cc"},"source":["!pip install transformers==3"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting transformers==3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\r\u001b[K     |▍                               | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 21.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 16.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 12.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 12.0MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 13.2MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 10.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 11.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737kB 11.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 11.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n","Collecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 26.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 37.1MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 39.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1623791732544,"user_tz":-120,"elapsed":23,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8bf91edf-3594-40ad-b5ad-6a38fbe8d9fa"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB","executionInfo":{"status":"ok","timestamp":1623791735319,"user_tz":-120,"elapsed":2787,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"data/trofi_xlm_mlm.csv\")\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"verb\", \"verb_idx\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1623791735338,"user_tz":-120,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"40ebbebf-18d1-442b-a7e2-be7eefebb7da"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"data/trofi_xlm_mlm.csv\")\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of training sentences: 3,737\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>verb</th>\n","      <th>sentence</th>\n","      <th>verb_idx</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>absorb</td>\n","      <td>An Energy Department spokesman says the sulfur...</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>absorb</td>\n","      <td>The yellow beta carotene pigment absorbs blue ...</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>absorb</td>\n","      <td>This time , the ground absorbed the shock wave...</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>absorb</td>\n","      <td>' Vitamins could be passed right out of the bo...</td>\n","      <td>12</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>absorb</td>\n","      <td>As Eliot wrote : '' In a warm haze , the sultr...</td>\n","      <td>14</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     verb                                           sentence  verb_idx  label\n","0  absorb  An Energy Department spokesman says the sulfur...        22      0\n","1  absorb  The yellow beta carotene pigment absorbs blue ...         5      0\n","2  absorb  This time , the ground absorbed the shock wave...         5      0\n","3  absorb  ' Vitamins could be passed right out of the bo...        12      0\n","4  absorb  As Eliot wrote : '' In a warm haze , the sultr...        14      0"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1","executionInfo":{"status":"ok","timestamp":1623791735340,"user_tz":-120,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623791735341,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a3c789cd-2df7-4d16-94f1-0e22d2307888"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values\n","labels = df.label.values\n","labels"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1623791737984,"user_tz":-120,"elapsed":2668,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"7ddb3a7f-0e8c-4ac7-90ec-1ffbb8eef002"},"source":["!pip install sentencepiece"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["39ae4b96ac9e422aba8cbd840bcc2e99","64307f381df748bbb8bb4fffe82217d0","5d2892d513c644148cccf40ee30a6aec","7fa21fbd5fc845a9a9f43f055756e8f8","1c31a4769bb043b78eab3fb54744b294","d2ca171d5904492fb0ea4e2c56096809","c00bdb2cf97447f9b75278feb2dd7a84","6d48eaeeaef14146980e65c740237db2"]},"executionInfo":{"status":"ok","timestamp":1623791739874,"user_tz":-120,"elapsed":1898,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9ae57f8d-8a96-4c8b-c394-b7d84c4446d1"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39ae4b96ac9e422aba8cbd840bcc2e99","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623791739876,"user_tz":-120,"elapsed":21,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"4081cc3a-bc37-4644-8d1c-34fc395634f7"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Original:  An Energy Department spokesman says the sulfur dioxide might be simultaneously recoverable through the use of powdered limestone , which tends to absorb the sulfur \n","Tokenized:  ['▁an', '▁energy', '▁department', '▁spoke', 'sman', '▁says', '▁the', '▁sul', 'fur', '▁', 'dioxid', 'e', '▁might', '▁be', '▁simultan', 'e', 'ously', '▁recover', 'able', '▁through', '▁the', '▁use', '▁of', '▁powder', 'ed', '▁lime', 'stone', '▁', ',', '▁which', '▁tend', 's', '▁to', '▁absorb', '▁the', '▁sul', 'fur']\n","Token IDs:  [142, 48302, 130625, 113091, 45211, 17378, 70, 2906, 11443, 6, 143961, 13, 13648, 186, 134477, 13, 79850, 192026, 2886, 8305, 70, 4527, 111, 173169, 297, 46844, 34165, 6, 4, 3129, 17660, 7, 47, 57622, 70, 2906, 11443]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1623791741678,"user_tz":-120,"elapsed":1812,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"819fd58e-dac6-42df-add9-a051395eeecf"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Original:  An Energy Department spokesman says the sulfur dioxide might be simultaneously recoverable through the use of powdered limestone , which tends to absorb the sulfur \n","Token IDs: tensor([     0,    142,  48302, 130625, 113091,  45211,  17378,     70,   2906,\n","         11443,      6, 143961,     13,  13648,    186, 134477,     13,  79850,\n","        192026,   2886,   8305,     70,   4527,    111, 173169,    297,  46844,\n","         34165,      6,      4,   3129,  17660,      7,     47,  57622,     70,\n","          2906,  11443,      2,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([0, 0, 0,  ..., 0, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1623791741679,"user_tz":-120,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a3de8b1a-0406-4f01-95de-30e79f366828"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["3,363 training samples\n","  374 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk","executionInfo":{"status":"ok","timestamp":1623791741680,"user_tz":-120,"elapsed":10,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0508fb7a69ca4bbe8b1a2ced595bc3c9","557affa966944986b1118001551d367b","b6cdb47ae18049f885249218a00ba296","2f61f214e0e64a7181c2a2b5ca9988d8","4ef914aad6084fd791c82a25676b84f1","6991f9c42c6645698341f594ef6c7c2f","f284adb3605f472cb31e3a52453f33ac","41a21ce334924d88931e1d77c4adcf9d","fbf1b9ad3adf40198b54b8897253edbe","b1bd37d0e02e4d23b1495e800df74f44","641fdf7d00484320ada0e201fb6556b7","13b92641239b4c0e93480c6a0823971d","898fff106eee4e6fb01391ad66ba25dc","eaea88fc232846e480b72b0395deb69e","1ef91824cbc2483bbb4850632aefcb86","3a2f8a2451444fd5a7397d842149093b"]},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1623791794794,"user_tz":-120,"elapsed":53123,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"cd9414d6-b506-47c7-a093-1f1f36b0ffea"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0508fb7a69ca4bbe8b1a2ced595bc3c9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbf1b9ad3adf40198b54b8897253edbe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1623791794795,"user_tz":-120,"elapsed":26,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ff7cc934-fc21-4c3a-e755-4281fa1b5fd9"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup","executionInfo":{"status":"ok","timestamp":1623791794796,"user_tz":-120,"elapsed":21,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg","executionInfo":{"status":"ok","timestamp":1623791794796,"user_tz":-120,"elapsed":20,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv","executionInfo":{"status":"ok","timestamp":1623791794797,"user_tz":-120,"elapsed":20,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR","executionInfo":{"status":"ok","timestamp":1623791794797,"user_tz":-120,"elapsed":18,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1623792247002,"user_tz":-120,"elapsed":452223,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ec705aed-deca-444c-88b7-0efd2eab53b5"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.69\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.59\n","  Validation Loss: 0.68\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.67\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.62\n","  Validation Loss: 0.67\n","  Validation took: 0:00:01\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.64\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation Loss: 0.62\n","  Validation took: 0:00:01\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.56\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 0.62\n","  Validation took: 0:00:01\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.46\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.64\n","  Validation took: 0:00:01\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.36\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 0.71\n","  Validation took: 0:00:01\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.28\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.81\n","  Validation took: 0:00:01\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.24\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.93\n","  Validation took: 0:00:01\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 1.01\n","  Validation took: 0:00:01\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    40  of    106.    Elapsed: 0:00:17.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","  Batch    80  of    106.    Elapsed: 0:00:33.\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([3, 128])\n","torch.Size([3, 128])\n","torch.Size([3])\n","\n","  Average training loss: 0.17\n","  Training epcoh took: 0:00:44\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 1.02\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:07:32 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1623792247014,"user_tz":-120,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8e1d963b-1216-45ef-e729-b4324f2b9ccf"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.69</td>\n","      <td>0.68</td>\n","      <td>0.59</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.67</td>\n","      <td>0.67</td>\n","      <td>0.62</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.64</td>\n","      <td>0.62</td>\n","      <td>0.68</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.56</td>\n","      <td>0.62</td>\n","      <td>0.70</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.46</td>\n","      <td>0.64</td>\n","      <td>0.71</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.36</td>\n","      <td>0.71</td>\n","      <td>0.70</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.28</td>\n","      <td>0.81</td>\n","      <td>0.72</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.24</td>\n","      <td>0.93</td>\n","      <td>0.71</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.19</td>\n","      <td>1.01</td>\n","      <td>0.71</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.17</td>\n","      <td>1.02</td>\n","      <td>0.71</td>\n","      <td>0:00:44</td>\n","      <td>0:00:01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.69         0.68           0.59       0:00:44         0:00:01\n","2               0.67         0.67           0.62       0:00:44         0:00:01\n","3               0.64         0.62           0.68       0:00:44         0:00:01\n","4               0.56         0.62           0.70       0:00:44         0:00:01\n","5               0.46         0.64           0.71       0:00:44         0:00:01\n","6               0.36         0.71           0.70       0:00:44         0:00:01\n","7               0.28         0.81           0.72       0:00:44         0:00:01\n","8               0.24         0.93           0.71       0:00:44         0:00:01\n","9               0.19         1.01           0.71       0:00:44         0:00:01\n","10              0.17         1.02           0.71       0:00:44         0:00:01"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1623792247832,"user_tz":-120,"elapsed":841,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"897cadfd-e9fb-4c64-f6b4-5b24545a6212"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792247834,"user_tz":-120,"elapsed":29,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9d35dd92-ebba-47c8-bded-988d677324c0"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","#test_df = pd.read_csv(\"Datasets/es_lcc_new.csv\")\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Number of test sentences: 3,737\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg","executionInfo":{"status":"ok","timestamp":1623792248207,"user_tz":-120,"elapsed":395,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dmz1QpXteUp","executionInfo":{"status":"ok","timestamp":1623792248875,"user_tz":-120,"elapsed":672,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K","executionInfo":{"status":"ok","timestamp":1623792248877,"user_tz":-120,"elapsed":52,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission[\"verb\"] = test_df['verb']\n","my_submission[\"verb_idx\"] = test_df[\"verb_idx\"]\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh","executionInfo":{"status":"ok","timestamp":1623792248878,"user_tz":-120,"elapsed":51,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc","executionInfo":{"status":"ok","timestamp":1623792248879,"user_tz":-120,"elapsed":50,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = final_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W","executionInfo":{"status":"ok","timestamp":1623792248881,"user_tz":-120,"elapsed":49,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"status":"ok","timestamp":1623792248882,"user_tz":-120,"elapsed":49,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b7bbc361-5c37-4557-a8e9-ea074c7cd2ca"},"source":["my_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>verb</th>\n","      <th>verb_idx</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1151</th>\n","      <td>Based on the number of acres planted in the sp...</td>\n","      <td>plant</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>538</th>\n","      <td>Allen J. Krowe , 56 years old , leaves his job...</td>\n","      <td>fill</td>\n","      <td>21</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>351</th>\n","      <td>Mr. Redford has assembled a great collection o...</td>\n","      <td>drink</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1108</th>\n","      <td>There were n't any American casualties reporte...</td>\n","      <td>miss</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1662</th>\n","      <td>Mr. Thunberg of Ried Thunberg said the Fed has...</td>\n","      <td>absorb</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence  ... label\n","1151  Based on the number of acres planted in the sp...  ...     0\n","538   Allen J. Krowe , 56 years old , leaves his job...  ...     0\n","351   Mr. Redford has assembled a great collection o...  ...     0\n","1108  There were n't any American casualties reporte...  ...     0\n","1662  Mr. Thunberg of Ried Thunberg said the Fed has...  ...     0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792248883,"user_tz":-120,"elapsed":48,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"17540330-4d11-4991-db9b-f095702990ba"},"source":["my_submission.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(374, 5)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792248885,"user_tz":-120,"elapsed":42,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"cb03b805-f561-4284-d6d5-4bd13eb03cc8"},"source":["test_df.label.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    226\n","1    148\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"nTtwGl9vxOoG","executionInfo":{"status":"ok","timestamp":1623792248885,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final = my_submission[(my_submission['correct_label'] == my_submission['label'])]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iVw1NZ2xO0C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792248888,"user_tz":-120,"elapsed":39,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"675b7bc8-5dc0-4b61-c8ab-0f371cadabde"},"source":["final.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(353, 5)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n","executionInfo":{"status":"ok","timestamp":1623792248890,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_met = my_submission[(my_submission['correct_label'] == 1) & (my_submission['label'] ==1)]"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792248891,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"83e175f1-e809-41f4-8b8b-5450718986ad"},"source":["final_met.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(134, 5)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"RFTH_BCexeY1","executionInfo":{"status":"ok","timestamp":1623792248892,"user_tz":-120,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_lit = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==0)]"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEwct9X5xehQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792248893,"user_tz":-120,"elapsed":35,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"6fa23f87-89af-4234-d91c-88dd57c8dfa5"},"source":["final_lit.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(219, 5)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"Rs-f8IKraTz5","executionInfo":{"status":"ok","timestamp":1623792248895,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#print(logits)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7","executionInfo":{"status":"ok","timestamp":1623792248895,"user_tz":-120,"elapsed":31,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission.to_csv('trofi_sub.csv', index=False)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GYFtiTEk7MP","executionInfo":{"status":"ok","timestamp":1623792248896,"user_tz":-120,"elapsed":31,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#final_met.to_csv(\"final_met.csv\", index=False)"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Whz6mWvpidb-"},"source":["#Save and load fine-tuned model"]},{"cell_type":"code","metadata":{"id":"73UumM0PhBym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792279134,"user_tz":-120,"elapsed":30269,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9661b490-32ec-4988-9d6b-149f89e7dcf0"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = 'mohx_xlmroberta/xlm-roberta_model_save'\n","# output_dir = './content/xlm-roberta_model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Saving model to mohx_xlmroberta/xlm-roberta_model_save\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('mohx_xlmroberta/xlm-roberta_model_save/sentencepiece.bpe.model',\n"," 'mohx_xlmroberta/xlm-roberta_model_save/special_tokens_map.json',\n"," 'mohx_xlmroberta/xlm-roberta_model_save/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"LmN96FOqjLKd"},"source":["#Import saved model and test"]},{"cell_type":"code","metadata":{"id":"ScJHWcE5hB4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792281883,"user_tz":-120,"elapsed":2757,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8cc42ccf-10e3-4528-9495-54ca7169c6c6"},"source":["!pip install transformers\n","\n","from transformers import XLMRobertaForSequenceClassification\n","\n","output_dir = 'mohx_xlmroberta/xlm-roberta_model_save'\n","\n","print(output_dir)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.95)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","mohx_xlmroberta/xlm-roberta_model_save\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SZbux55ucvy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623792303597,"user_tz":-120,"elapsed":21718,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"dd151d04-786c-40a7-e4fe-f74b3ac52b4a"},"source":["from transformers import XLMRobertaTokenizer\n","import torch\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n","model_loaded = XLMRobertaForSequenceClassification.from_pretrained(output_dir)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lhw_GFdIuwR4","executionInfo":{"status":"ok","timestamp":1623792303600,"user_tz":-120,"elapsed":22,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":[""],"execution_count":47,"outputs":[]}]}