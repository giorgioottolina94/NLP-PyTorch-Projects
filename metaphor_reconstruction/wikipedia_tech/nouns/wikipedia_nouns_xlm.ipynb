{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"wikipedia_nouns_xlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935146962,"user_tz":-120,"elapsed":447,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"28fff819-9937-401e-b6cd-2b213ab5d404"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935149448,"user_tz":-120,"elapsed":2174,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e1de5ef3-35fd-48ab-f743-6e62bbfb942d"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935149803,"user_tz":-120,"elapsed":370,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"089bb499-63b1-40af-e191-e937ac17d506"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L","executionInfo":{"status":"ok","timestamp":1629935149804,"user_tz":-120,"elapsed":7,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935153076,"user_tz":-120,"elapsed":3278,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"d7aad6fa-fbce-40ab-a0f7-a8df2881f59e"},"source":["!pip install transformers==3"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1629935153077,"user_tz":-120,"elapsed":44,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"bdd0f277-9c1a-499a-9a8b-916ae05e691c"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB","executionInfo":{"status":"ok","timestamp":1629935153404,"user_tz":-120,"elapsed":361,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"stockholm/wikipedia_tech/nouns/wiki_tech_labels_500.csv\")\n","data = data.rename(columns={'prediction': 'label'})\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1629935153409,"user_tz":-120,"elapsed":24,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"055dc840-c971-43bf-d312-1f4218c2deae"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"stockholm/wikipedia_tech/nouns/wiki_tech_labels_500.csv\")\n","df = df.rename(columns={'prediction': 'label'})\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of training sentences: 499\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['Technology (\"science of craft\", from Greek τ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Technology can be the knowledge of techniques...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Systems (e</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>g</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>machines) applying technology by taking an in...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  ['Technology (\"science of craft\", from Greek τ...      0\n","1   Technology can be the knowledge of techniques...      1\n","2                                         Systems (e      0\n","3                                                  g      0\n","4   machines) applying technology by taking an in...      0"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1","executionInfo":{"status":"ok","timestamp":1629935153411,"user_tz":-120,"elapsed":20,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935153412,"user_tz":-120,"elapsed":20,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2ca631e8-be6b-4da5-d0aa-0738c653788e"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values.astype(str)\n","labels = df.label.values\n","labels"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n","       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n","       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n","       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n","       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1629935156397,"user_tz":-120,"elapsed":3001,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c205dd18-5878-4527-9443-255040cd111d"},"source":["!pip install sentencepiece"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935157656,"user_tz":-120,"elapsed":1269,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a5d72039-17b8-4156-9e9e-7981961a59d8"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935157658,"user_tz":-120,"elapsed":13,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"06410ad0-bb6b-4260-fd5d-0a37519b7924"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Original:  ['Technology (\"science of craft\", from Greek τέχνη, techne, \"art, skill, cunning of hand\"; and -λογία, -logia) is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation\n","Tokenized:  ['▁[', \"'\", 'tech', 'n', 'ology', '▁(\"', 'science', '▁of', '▁craft', '\",', '▁from', '▁gre', 'ek', '▁', 'τέ', 'χ', 'νη', ',', '▁tech', 'ne', ',', '▁\"', 'art', ',', '▁skill', ',', '▁cun', 'ning', '▁of', '▁hand', '\";', '▁and', '▁-', 'λογ', 'ία', ',', '▁-', 'logia', ')', '▁is', '▁the', '▁sum', '▁of', '▁techniques', ',', '▁skills', ',', '▁methods', ',', '▁and', '▁process', 'es', '▁used', '▁in', '▁the', '▁production', '▁of', '▁good', 's', '▁or', '▁services', '▁or', '▁in', '▁the', '▁accomplish', 'ment', '▁of', '▁objective', 's', ',', '▁such', '▁as', '▁scientific', '▁investigation']\n","Token IDs:  [378, 25, 20489, 19, 25443, 24073, 175201, 111, 131346, 830, 1295, 3514, 343, 6, 16012, 2088, 9417, 4, 51216, 86, 4, 44, 3960, 4, 112419, 4, 19466, 592, 111, 3535, 56128, 136, 20, 25892, 3420, 4, 20, 81331, 16, 83, 70, 10554, 111, 53088, 4, 59376, 4, 150624, 4, 136, 9433, 90, 11814, 23, 70, 36049, 111, 4127, 7, 707, 11374, 707, 23, 70, 163846, 674, 111, 151814, 7, 4, 6044, 237, 57456, 145456]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1629935158108,"user_tz":-120,"elapsed":459,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e1c64425-4ce6-4f2b-9d0b-5aba8c8a708d"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Original:  ['Technology (\"science of craft\", from Greek τέχνη, techne, \"art, skill, cunning of hand\"; and -λογία, -logia) is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation\n","Token IDs: tensor([     0,    378,     25,  20489,     19,  25443,  24073, 175201,    111,\n","        131346,    830,   1295,   3514,    343,      6,  16012,   2088,   9417,\n","             4,  51216,     86,      4,     44,   3960,      4, 112419,      4,\n","         19466,    592,    111,   3535,  56128,    136,     20,  25892,   3420,\n","             4,     20,  81331,     16,     83,     70,  10554,    111,  53088,\n","             4,  59376,      4, 150624,      4,    136,   9433,     90,  11814,\n","            23,     70,  36049,    111,   4127,      7,    707,  11374,    707,\n","            23,     70, 163846,    674,    111, 151814,      7,      4,   6044,\n","           237,  57456, 145456,      2,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n","        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n","        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n","        1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1629935158110,"user_tz":-120,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8ab4b657-ef3b-4df5-99af-5dbc2559e359"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["  449 training samples\n","   50 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk","executionInfo":{"status":"ok","timestamp":1629935158112,"user_tz":-120,"elapsed":12,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1629935173975,"user_tz":-120,"elapsed":15874,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ce3297f3-dffc-4c22-ef74-8a44bbfff4ab"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1629935173977,"user_tz":-120,"elapsed":40,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"24e4a5b5-ed64-457b-a2e8-d19703f099d0"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup","executionInfo":{"status":"ok","timestamp":1629935173979,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg","executionInfo":{"status":"ok","timestamp":1629935173980,"user_tz":-120,"elapsed":36,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv","executionInfo":{"status":"ok","timestamp":1629935173980,"user_tz":-120,"elapsed":35,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR","executionInfo":{"status":"ok","timestamp":1629935173981,"user_tz":-120,"elapsed":36,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1629935235526,"user_tz":-120,"elapsed":61580,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b084f009-8f73-4138-b62c-5c44979f2490"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.68\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.63\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.56\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.58\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.47\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.52\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.35\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.48\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.25\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.51\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.69\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation Loss: 0.51\n","  Validation took: 0:00:00\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.11\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.84\n","  Validation Loss: 0.54\n","  Validation took: 0:00:00\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.80\n","  Validation Loss: 0.60\n","  Validation took: 0:00:00\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.80\n","  Validation Loss: 0.60\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Total training took 0:01:01 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1629935235530,"user_tz":-120,"elapsed":52,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"333a6283-dbe6-4022-f6b0-d104bc8286c3"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.68</td>\n","      <td>0.63</td>\n","      <td>0.72</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.56</td>\n","      <td>0.58</td>\n","      <td>0.71</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.47</td>\n","      <td>0.52</td>\n","      <td>0.77</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.35</td>\n","      <td>0.48</td>\n","      <td>0.81</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.25</td>\n","      <td>0.51</td>\n","      <td>0.77</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.19</td>\n","      <td>0.69</td>\n","      <td>0.81</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.15</td>\n","      <td>0.51</td>\n","      <td>0.85</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.11</td>\n","      <td>0.54</td>\n","      <td>0.84</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.07</td>\n","      <td>0.60</td>\n","      <td>0.80</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.07</td>\n","      <td>0.60</td>\n","      <td>0.80</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.68         0.63           0.72       0:00:06         0:00:00\n","2               0.56         0.58           0.71       0:00:06         0:00:00\n","3               0.47         0.52           0.77       0:00:06         0:00:00\n","4               0.35         0.48           0.81       0:00:06         0:00:00\n","5               0.25         0.51           0.77       0:00:06         0:00:00\n","6               0.19         0.69           0.81       0:00:06         0:00:00\n","7               0.15         0.51           0.85       0:00:06         0:00:00\n","8               0.11         0.54           0.84       0:00:06         0:00:00\n","9               0.07         0.60           0.80       0:00:06         0:00:00\n","10              0.07         0.60           0.80       0:00:06         0:00:00"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1629935236026,"user_tz":-120,"elapsed":543,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e173d0da-e19f-4f07-e041-7db77312e135"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUddbA8e9MkknvvZBCYJIASUiAQCjSRECwIQirS7G7a3t1Lbjqrrrv7r6ia0FXd1UsIEWqgAiioEgPoZeEEgiQHtLrzCRz3z8CgZgEAiS5E3I+z8Oj3HrmcJM585tf0SiKoiCEEEIIIYRQjVbtAIQQQgghhOjspCgXQgghhBBCZVKUCyGEEEIIoTIpyoUQQgghhFCZFOVCCCGEEEKoTIpyIYQQQgghVCZFuRDihpWRkUFERAQffPDBNV9j5syZREREtGJUN67m8h0REcHMmTNbdI0PPviAiIgIMjIyWj2+5cuXExERwc6dO1v92kIIcb2s1Q5ACNF5XE1xu2HDBoKCgtowmo6nsrKS//znP3z//ffk5eXh4eFBnz59+OMf/0h4eHiLrvHUU0/xww8/8O233xIVFdXkMYqiMHLkSEpLS9myZQt2dnat+TLa1M6dO0lKSmL69Om4uLioHU4jGRkZjBw5kvvuu4+//OUvaocjhLAgUpQLIdrNrFmzGvx99+7dfPPNN0yePJk+ffo02Ofh4XHd9wsMDOTAgQNYWVld8zX+9re/8frrr193LK3hlVdeYc2aNYwfP56EhATy8/PZuHEj+/fvb3FRPnHiRH744QeWLVvGK6+80uQxO3bsIDMzk8mTJ7dKQX7gwAG02vb5YjYpKYkPP/yQu+66q1FRfscddzBu3DhsbGzaJRYhhLgaUpQLIdrNHXfc0eDvtbW1fPPNN/Tu3bvRvt8qLy/Hycnpqu6n0WiwtbW96jgvZSkFXFVVFevWrWPw4MH861//qt/+xBNPYDQaW3ydwYMH4+/vz+rVq3nhhRfQ6XSNjlm+fDlQV8C3huv9N2gtVlZW1/UBTQgh2pL0KRdCWJwRI0YwdepUjhw5woMPPkifPn24/fbbgbri/N1332XSpEn079+fXr16MWrUKN5++22qqqoaXKepPs6Xbvv555+5++67iY6OZvDgwbz55pvU1NQ0uEZTfcovbCsrK+Ovf/0riYmJREdHM2XKFPbv39/o9RQVFfHSSy/Rv39/4uLimDZtGkeOHGHq1KmMGDGiRTnRaDRoNJomPyQ0VVg3R6vVctddd1FcXMzGjRsb7S8vL2f9+vXo9XpiYmKuKt/NaapPudls5r///S8jRowgOjqa8ePHs2rVqibPT0tL47XXXmPcuHHExcURGxvLhAkTWLJkSYPjZs6cyYcffgjAyJEjiYiIaPDv31yf8sLCQl5//XWGDh1Kr169GDp0KK+//jpFRUUNjrtw/vbt25kzZw4333wzvXr1YvTo0axYsaJFubgaqampPP744/Tv35/o6GhuvfVWPv30U2praxscl52dzUsvvcTw4cPp1asXiYmJTJkypUFMZrOZL7/8kttuu424uDji4+MZPXo0f/7znzGZTK0euxDi6klLuRDCImVlZTF9+nTGjBnDLbfcQmVlJQC5ubksXbqUW265hfHjx2NtbU1SUhKfffYZKSkpzJkzp0XX37RpEwsWLGDKlCncfffdbNiwgc8//xxXV1cee+yxFl3jwQcfxMPDg8cff5zi4mK++OILHnnkETZs2FDfqm80Grn//vtJSUlhwoQJREdHc/ToUe6//35cXV1bnA87OzvuvPNOli1bxnfffcf48eNbfO5vTZgwgY8//pjly5czZsyYBvvWrFlDdXU1d999N9B6+f6tf/7zn8ydO5d+/foxY8YMCgoKeOONN+jSpUujY5OSkkhOTmbYsGEEBQXVf2vwyiuvUFhYyKOPPgrA5MmTKS8v58cff+Sll17C3d0duPxYhrKyMn73u99x+vRp7r77bnr06EFKSgoLFy5kx44dLFmypNE3NO+++y7V1dVMnjwZnU7HwoULmTlzJsHBwY26YV2rgwcPMnXqVKytrbnvvvvw8vLi559/5u233yY1NbX+25Kamhruv/9+cnNzuffeewkNDaW8vJyjR4+SnJzMXXfdBcDHH3/M7NmzGT58OFOmTMHKyoqMjAw2btyI0Wi0mG+EhOjUFCGEUMmyZcsUvV6vLFu2rMH24cOHK3q9Xlm8eHGjcwwGg2I0Ghttf/fddxW9Xq/s37+/ftvZs2cVvV6vzJ49u9G22NhY5ezZs/XbzWazMm7cOGXQoEENrvviiy8qer2+yW1//etfG2z//vvvFb1eryxcuLB+29dff63o9Xrlo48+anDshe3Dhw9v9FqaUlZWpjz88MNKr169lB49eihr1qxp0XnNmTZtmhIVFaXk5uY22H7PPfcoPXv2VAoKChRFuf58K4qi6PV65cUXX6z/e1pamhIREaFMmzZNqampqd9+6NAhJSIiQtHr9Q3+bSoqKhrdv7a2Vvn973+vxMfHN4hv9uzZjc6/4MLztmPHjvpt77zzjqLX65Wvv/66wbEX/n3efffdRuffcccdisFgqN+ek5Oj9OzZU3nmmWca3fO3LuTo9ddfv+xxkydPVqKiopSUlJT6bWazWXnqqacUvV6vbNu2TVEURUlJSVH0er3yySefXPZ6d955pzJ27NgrxieEUI90XxFCWCQ3NzcmTJjQaLtOp6tv1aupqaGkpITCwkIGDhwI0GT3kaaMHDmywewuGo2G/v37k5+fT0VFRYuuMWPGjAZ/HzBgAACnT5+u3/bzzz9jZWXFtGnTGhw7adIknJ2dW3Qfs9nM008/TWpqKmvXruWmm27iueeeY/Xq1Q2Oe/XVV+nZs2eL+phPnDiR2tpavv322/ptaWlp7Nu3jxEjRtQPtG2tfF9qw4YNKIrC/fff36CPd8+ePRk0aFCj4x0cHOr/32AwUFRURHFxMYMGDaK8vJyTJ09edQwX/Pjjj3h4eDB58uQG2ydPnoyHhwc//fRTo3PuvffeBl2GfH19CQsLIz09/ZrjuFRBQQF79+5lxIgRREZG1m/XaDT84Q9/qI8bqH+Gdu7cSUFBQbPXdHJyIjc3l+Tk5FaJUQjR+qT7ihDCInXp0qXZQXnz589n0aJFnDhxArPZ3GBfSUlJi6//W25ubgAUFxfj6Oh41de40F2iuLi4fltGRgY+Pj6NrqfT6QgKCqK0tPSK99mwYQNbtmzhrbfeIigoiPfff58nnniCF154gZqamvouCkePHiU6OrpFfcxvueUWXFxcWL58OY888ggAy5YtA6jvunJBa+T7UmfPngWga9eujfaFh4ezZcuWBtsqKir48MMPWbt2LdnZ2Y3OaUkOm5ORkUGvXr2wtm74dmhtbU1oaChHjhxpdE5zz05mZuY1x/HbmAC6devWaF/Xrl3RarX1OQwMDOSxxx7jk08+YfDgwURFRTFgwADGjBlDTExM/XnPPvssjz/+OPfddx8+Pj4kJCQwbNgwRo8efVVjEoQQbUeKciGERbK3t29y+xdffMH//d//MXjwYKZNm4aPjw82Njbk5uYyc+ZMFEVp0fUvNwvH9V6jpee31IWBif369QPqCvoPP/yQP/zhD7z00kvU1NQQGRnJ/v37+fvf/96ia9ra2jJ+/HgWLFjAnj17iI2NZdWqVfj5+TFkyJD641or39fjT3/6E7/88gv33HMP/fr1w83NDSsrKzZt2sSXX37Z6INCW2uv6R1b6plnnmHixIn88ssvJCcns3TpUubMmcNDDz3E888/D0BcXBw//vgjW7ZsYefOnezcuZPvvvuOjz/+mAULFtR/IBVCqEeKciFEh7Jy5UoCAwP59NNPGxRHv/76q4pRNS8wMJDt27dTUVHRoLXcZDKRkZHRogVuLrzOzMxM/P39gbrC/KOPPuKxxx7j1VdfJTAwEL1ez5133tni2CZOnMiCBQtYvnw5JSUl5Ofn89hjjzXIa1vk+0JL88mTJwkODm6wLy0trcHfS0tL+eWXX7jjjjt44403Guzbtm1bo2trNJqrjuXUqVPU1NQ0aC2vqakhPT29yVbxtnahW9WJEyca7Tt58iRms7lRXF26dGHq1KlMnToVg8HAgw8+yGeffcYDDzyAp6cnAI6OjowePZrRo0cDdd+AvPHGGyxdupSHHnqojV+VEOJKLOvjvhBCXIFWq0Wj0TRooa2pqeHTTz9VMarmjRgxgtraWubOndtg++LFiykrK2vRNYYOHQrUzfpxaX9xW1tb3nnnHVxcXMjIyGD06NGNumFcTs+ePYmKiuL7779n/vz5aDSaRnOTt0W+R4wYgUaj4Ysvvmgwvd/hw4cbFdoXPgj8tkU+Ly+v0ZSIcLH/eUu71dx8880UFhY2utbixYspLCzk5ptvbtF1WpOnpydxcXH8/PPPHDt2rH67oih88sknAIwaNQqomz3mt1Ma2tra1ncNupCHwsLCRvfp2bNng2OEEOqSlnIhRIcyZswY/vWvf/Hwww8zatQoysvL+e67766qGG1PkyZNYtGiRbz33nucOXOmfkrEdevWERIS0mhe9KYMGjSIiRMnsnTpUsaNG8cdd9yBn58fZ8+eZeXKlUBdgfXvf/+b8PBwxo4d2+L4Jk6cyN/+9jc2b95MQkJCoxbYtsh3eHg49913H19//TXTp0/nlltuoaCggPnz5xMZGdmgH7eTkxODBg1i1apV2NnZER0dTWZmJt988w1BQUEN+u8DxMbGAvD2229z2223YWtrS/fu3dHr9U3G8tBDD7Fu3TreeOMNjhw5QlRUFCkpKSxdupSwsLA2a0E+dOgQH330UaPt1tbWPPLII7z88stMnTqV++67j3vvvRdvb29+/vlntmzZwvjx40lMTATquja9+uqr3HLLLYSFheHo6MihQ4dYunQpsbGx9cX5rbfeSu/evYmJicHHx4f8/HwWL16MjY0N48aNa5PXKIS4Opb5LiaEEM148MEHURSFpUuX8ve//x1vb2/Gjh3L3Xffza233qp2eI3odDq++uorZs2axYYNG1i7di0xMTF8+eWXvPzyy1RXV7foOn//+99JSEhg0aJFzJkzB5PJRGBgIGPGjOGBBx5Ap9MxefJknn/+eZydnRk8eHCLrnvbbbcxa9YsDAZDowGe0Hb5fvnll/Hy8mLx4sXMmjWL0NBQ/vKXv3D69OlGgyvfeust/vWvf7Fx40ZWrFhBaGgozzzzDNbW1rz00ksNju3Tpw/PPfccixYt4tVXX6WmpoYnnnii2aLc2dmZhQsXMnv2bDZu3Mjy5cvx9PRkypQpPPnkk1e9imxL7d+/v8mZa3Q6HY888gjR0dEsWrSI2bNns3DhQiorK+nSpQvPPfccDzzwQP3xERERjBo1iqSkJFavXo3ZbMbf359HH320wXEPPPAAmzZtYt68eZSVleHp6UlsbCyPPvpogxlehBDq0SjtMUpHCCFEA7W1tQwYMICYmJhrXoBHCCHEjUP6lAshRBtrqjV80aJFlJaWNjkvtxBCiM5Huq8IIUQbe+WVVzAajcTFxaHT6di7dy/fffcdISEh3HPPPWqHJ4QQwgJI9xUhhGhj3377LfPnzyc9PZ3Kyko8PT0ZOnQoTz/9NF5eXmqHJ4QQwgJIUS6EEEIIIYTKpE+5EEIIIYQQKpOiXAghhBBCCJXJQM/ziooqMJvbtyePp6cTBQXl7XpPSyb5aEjycZHkQgghxI1Aq9Xg7u7Y5D4pys8zm5V2L8ov3FdcJPloSPJxkeRCCCHEjUy6rwghhBBCCKEyVVvKjUYj77//PitXrqS0tJTIyEieeeYZEhMTL3veiBEjyMzMbHJfSEgI69evb4twhRBCCCGEaBOqFuUzZ85k/fr1TJs2jZCQEFasWMHDDz/MvHnziIuLa/a8P//5z1RUVDTYlpWVxXvvvSer4wkhhBBCiA5HtaL8wIEDrFmzhpdeeokZM2YAcOeddzJ+/Hjefvtt5s+f3+y5N998c6NtH330EQC33XZbm8QrhBBCCCFEW1GtT/m6deuwsbFh0qRJ9dtsbW2ZOHEiu3fvJi8v76qu99133xEUFER8fHxrhyqEEEIIIUSbUq0oT0lJISwsDEfHhtPCxMTEoCgKKSkpLb7WkSNHSEtLY/z48a0dphBCCCGEEG1OtaI8Pz8fHx+fRtu9vb0BrqqlfPXq1QDcfvvtrROcEEIIIYQQ7Ui1PuXV1dXY2Ng02m5rawuAwWBo0XXMZjNr1qyhR48ehIeHX3M8np5O13zu9fD2dlblvpZK8tGQ5OMiyYUQQogbmWpFuZ2dHSaTqdH2C8X4heL8SpKSksjNza0fLHqtCgrK231xEm9vZ/Lzy9r1npZM8tGQ5OMiyYUQQogbgVarabYhWLWi3Nvbu8kuKvn5+QBNdm1pyurVq9FqtYwbN65V4xNCCGHZknL2sCptHUWGYtxt3bg9fAwJfjLYXwjRManWpzwyMpJTp041mm98//799fuvxGg0sn79ehISEvD19W2TOIUQQliepJw9LEhdRpGhGIAiQzELUpeRlLNH5ciEEOLaqFaUjxkzBpPJxJIlS+q3GY1Gli9fTnx8fH2RnZWVRVpaWpPX2LRpE6WlpTI3uRBCdDKr0tZhMjfsAmkym1iVtk6liIQQ4vqo1n0lNjaWMWPG8Pbbb5Ofn09wcDArVqwgKyuLf/7zn/XHvfjiiyQlJXH06NFG11i9ejU6nY7Ro0e3Z+hCCCFUdqGFvKXbhRDC0qlWlAPMmjWL9957j5UrV1JSUkJERASffPIJffr0ueK55eXl/PLLLwwbNgxnZ5mVQQghOgtFUdBpdRjNxkb73G3dVIhICCGun0ZRlPadcsRCyewr6pN8NCT5uEhyIS61KWMbi499i1ajxayY67drNVqmRt0jgz2FEBbLImdf6cy2H85h+aY0CksNeLjYMmFoOIk9/dQOSwghLN7xopMsPb6KXp5RxPvEsPrkDxQZirG1ssVQa0CrUW2olBBCXBcpytvZ9sM5fLU2FWNNXetOQamBr9amAkhhLoQQl1FUXcycQ1/jZe/BjJ5TsLe2p79/XXfHGnMNs/d+wtcpS/Bz8CHIOUDlaIUQ4upIk0I7W74prb4gv8BYY2b5pqZnmBFCCAGmWhOfHpqH0Wzkkejp2FvbN9hvrbXmwV5TcbC255ODc6kwVaoUqRBCXBspyttZQanhqrYLIURnpygK3xz7ltOlZ5nWYwr+jk2vS+Fq68zD0VMpNpTwxeEFDfqbCyGEpZOivJ15utg2ud1OZ0WtWd5AhBDitzZn7mB79i7GhI6kt3evyx4b5hrCZP2dpBQeY/XJH9opQiGEuH5SlLezCUPD0Vk3TLtWq6HaWMt7Sw5QWW1q5kwhhOh8ThSfYsnxlfT0jGRc2KgWnTMosD+DAvqz/vTP7Mk70MYRCiFE65CivJ0l9vRj+thIPF1s0VDXcv7guChmjI0k9XQRf5+3m9wi6QsphBDFhhI+OzQPTzt3ZvT43VXNrDJJfwdhLsHMS1lMVnlOG0YphBCtQ+YpP88S5ik/eqaIf684hKIoPH5XNJEh7u0aj9pkLuqGJB8XSS46H5O5hvf2/Iesihye7/MEAU5XPztVsaGEN3fNxtZKxwt9n8LBxv7KJwkhRBu63Dzl0lJuQSKC3XllWh9cHHX865t9/Lo/S+2QhBBCFUuOfUt66RmmRU2+poIcwM3WlQd7/Z6C6iK+PLJQBn4KISyaFOUWxsfdgZen9iUq1J0v16ay8Kfj7d6CL4QQatqcuYOtWUmMDhlBnE/0dV2rm1sYk7rfzuGCVL4/9VMrRSiEEK1PinIL5GBnzdMTYxjVtws/Jp/l/aUHqDLUqB2WEEK0uZMl6Sw5tpIeHhGM73pLq1xzSGAiA/z7sjb9J/bnH26VawohRGuTotxCWWm1/O7m7kwbHcGR9EL+Pm83ecVVaoclhBBtpthQwqcH5+Fu58b9Pa9uYOflaDQapujvItg5iLlHFpFTkdcq1xVCiNYkRbmFGxYXyLOTe1NSbuB/v0rm2NlitUMSQohWZzLX8NnBr6muNfBo9HQcbBxa9fo2VjY8Ej0Na601nxz8iqqa6la9vhBCXC8pyjuAqBB3XpnWFyd7G95auJfNB2QAqBDixrL02EpOlZ5matQ91zyw80rc7dx4qNfvya8qYO6Rb2TgpxDCokhR3kH4ejjwyrQ+RAa78cX3qSzeeEIGgAohbghbM3eyJWsno4KHEe8T06b36u4ezoRu4zlw7jA/pG9s03sJIcTVkKK8A3Gws+F/7ollZHwQ65LO8MEyGQAqhOjYTpWcZvGxb4ny0HN7+Jh2ueewoEH0841nzakfOXQupV3uKYQQVyJFeQdjpdVy3y16fn+LnoMnC/nH17s5JwNAhRAdUImhlE8PzsXV1pX7e97bagM7r0Sj0XBv5ASCnPz58shC8irz2+W+QghxOVKUd1Aj4oN4ZnIsRaUG/jY3meMZMgBUCNFx1Jhr+OzQ11TVVPNozHQcW3lg55XorHQ8HD0NrUbLfw/OpVoGfgohVCZFeQfWM9SDl6f1wcHWmrcW7mXrwWy1QxJCiBZZdnw1J0vS+X3UJAKd/FWJwdPegwd63kduRR7zUpagKDJORwihHinKOzh/T0dentaX7kFuzFmTwtJf0jDLG4sQwoJty9rFr5nbuTl4KH18e6saS6RHd+7sdiv78g/y4+lfVI1FCNG5SVF+A3Cyt+GZe2IZ1juA73ec5t/LD1JtlAGgQgjLk156hm+OLifSvTu3d22fgZ1XMrLLTfTxiWXVyXUcLjiqdjhCiE5KinIVJOXs4ZWt/2DyN3/gla3/IClnz3Vf09pKy9TREdx7c3f2nTjHP7/eQ0GJ9JEUQliOUmMZnx6ch6utC/f3uhcrrZXaIQF1Az/vi5qEv6MvXx5ewLmqArVDEkJ0QlKUt7OknD0sSF1GkaEYBSgyFLMgdVmrFOYajYab+3bhmUmxnCup4m9zk0nLLLn+oIUQ4jrVnF+xs8JUycPR03GycVQ7pAZsrXQ8Ej0dgE8OzsVQa1Q5IiFEZyNFeTtblbYOk9nUYJvJbGJV2rpWu0evrp68PLUvtjZa3lywlx2Hc1rt2kIIcS2Wn/iOtJJT/D5yIl2cA9QOp0neDp7c3/NesspzmC8DP4UQ7UyK8nZWZGh66sLmtl+rAC9HXp3ej/AAFz5ZfYTlv8oAUCGEOrZnJ7MpYxsju9xEX784tcO5rB6eEdzedQy78/az4eyvaocjhOhEpChvZ+62bs3ue2f3x+zM3o2x1tTsMVfDyd6GP03pzU2x/ny37TQfrziEwVjbKtcWQoiWOF16lkVHl6N378Yd4WPVDqdFRoUMI847mm9PfE9q4XG1wxFCdBJWr7322mtqB2EJqqqMtEdDspPOkSMFRzEr5vptNlob4ryjyavKZ3t23VRhxYYSXHUuuNg6X9f9tFoNsd28cLC15qfdGRw8WUhMuCf2ttbX+1JanaOjLZWV0o/zAsnHRZKLjqnMWM77ez/BztqOJ3s/jJ21rdohtYhGo6GHZwT7zx1hZ04y8T4xONjYqx2WEOIGoNFocHDQNblPivLz2qsoD3Tyx8POnTOlGRhqq3G3dWOi/nbGdx3N0KBBdHcPp7q2ml25e/k1cxuHz6UC4OPghbX22gppjUZDeKArYf7ObNqXxdZDOeiD3HB3tqw3SCm8GpJ8XCS56HhqzbX858CX5Fed48neD+Pt4Kl2SFfFWmtNlEd3tmTtJLXwGAl+fSxmthghRMd1uaJco8hIFgAKCsoxm9s3Fd7ezuTnlzW5r8JUSVLOHrZm7SS7IhedlY6+Pr0ZFJhAiHMXNBrNNd0zM7+c95ceoKTCyIPjokiI8r2el9CqLpePzkjycZHkouNZcmwlv2RsZXqPKST4xasdzjU7dC6F/xz4kr6+cUzvMfmaf/cKIQTU9WDw9HRqcp+0lJ/XXi3ll7pc65/OyoYw12CGBCbSwzOCGnMtu3P3sTlzB/vyD2FWzPg4eGFjZXNV93Rx1NG/py/HzxazftdZFEVBH+xmEW800hrakOTjIslFx7IzezcrT65leJfBjAoZpnY418XHwRsNGn7J2IKDjQNhrsFqhySE6MCk+0oLWFpRfoFGo8Hdzo0Y754MDRqEp507meXZbM/exS8ZW8ipyMfRxh4PO/cWF9a2NlYM6OFHcZmBH5MzyC6oJCbcE2srdcf9SuHVkOTjIslFx3GmNINPD80l3DWU6T2moNV0/PkEwt1CySzPZlPmNrq7heFp76F2SEKIDkqK8haw1KL8UjZaa4Jdghgc2J8Yr56Awr78g2zJ2kly3j5MtSZ8HLywtWr6H/tSVloNvbt7Yaez5qfksxw6VUhMuJeqA0Cl8GpI8nGR5KJjKDOWM3vvJ+isdDwZ9zB21nZqh9QqNBoNPT0j2Zd/kJ05u+nr2xv7G+S1CSHalxTlLdARivJLudo608srimFBg/B18Ca3sm7mlp/PbiGzPBs7azs87T0u23qu0WjoFuRKiK8zv+zPYtuhbCKC3XBzUmcAqBReDUk+LpJcWL4LAzvzqvJ5ovdD+Dh4qR1Sq7LRWhPh3p0tmTtILTpBf794GfgphLhqUpS3QEcryi+w0loR5BxAYkA/+vjEoNVoOXDuMFuzktiZsxtDjQEve4/Ltur4eToQG+7FrpRcNu7OxM/DgQCv9l8CWwqvhiQfF0kuLN+KE2vYnbef30dOoqdXpNrhtAknnSN+jj5sPLuZYmMpMV49LGI8jhCi47DY2VeMRiPvv/8+K1eupLS0lMjISJ555hkSExNbdP7q1av56quvOHHiBDqdDr1ezwsvvEBMTMxVx2Jps69cD5O5hgP5h9iWtYvUouNoqPvqdWBAAr08I5tt3SmtMPLh8oOcyCzhriFhjB8Y2q5vODLDRkOSj4skF5YtKWcPXx1ZxLCgQUzS36F2OG3uu5M/sDZ9A5P1d3FTUMver4QQAix49pXnn3+e5cuXc88993Dbbbdx9OhR5syZQ2JiIv7+/pc9991332XWrFkMHDiQyZMnExcXh8lkws/Pj65du151LB21pVOhG/AAACAASURBVLwpVhotAU5+9PfvQ3+/eHRWOo4UpLItO4ltWUlUmKrwtHfHwcahwXm2OisG9PSloKRuAGhuURUxXT2xaqcBoNIa2pDk4yLJheU6W5bJJwe/oqtrCDN6/O6GGNh5Jd3cunKmLINNmdvQu4fjYeeudkhCiA7CIlvKDxw4wKRJk3jppZeYMWMGAAaDgfHjx+Pj48P8+fObPXfPnj3ce++9fPDBB4waNapV4rmRWsqbUmuu5XBBKluzkjhckIqCQoR7NwYFJBDj3QubSxYmUhSF73ecZvmmk4T6u/Dk3dHt0s9cWkMbknxcJLmwTOXGCt5Mno1ZMTOz39M465pu/bkRVZqqmJU8m+paAzP7PY2bravaIQkhOoDLtZSr1qSxbt06bGxsmDRpUv02W1tbJk6cyO7du8nLy2v23Llz5xIdHc2oUaMwm81UVFS0R8gdmpXWihjvnvwh9n7+NvAlxofdQn5VAZ8fXsArW//OsuOryanIBeo+xY1LDOXxCdFknivnb18lczpHCiIhxEW15lrmHJ5PqbGMR6KndaqCHMDBxp5HoqdjqDXy2cF5mMw1aockhOjgVCvKU1JSCAsLw9Gx4YDCmJgYFEUhJSWl2XO3b99OdHQ077zzDn369CE+Pp4RI0awatWqtg77huBu58bYsJt5PfFFnoh9iO5uXfklYyt/2/kv3tn9ETuykzHWGonXe/Pn3/cB4J/zd7P7aL7KkQshLMXKtLUcKzrBlIgJhLh0UTscVQQ4+TE16h5OlZ5hybGVaocjRJOScvbwytZ/8PjGF3hl6z9IytmjdkiiGapNSp2fn4+vb+Ml3r29vQGabSkvKSmhuLiYNWvWYGVlxXPPPYebmxvz58/n+eefx97evtW6tNzotBotUZ56ojz1lBnL2ZGdzLbsJOalLGbp8VX0841jYEB//jK9Lx8sP8i/Vxzk7qFduXVAiMw4IEQnlpyzlw1nf+WmwIEk+vdVOxxVxfvEcDZkOOtP/0yIcxCDAvurHZIQ9ZJy9rAgdRkmswmAIkMxC1KXAZDgF69maKpJytnDqrR1FBmKcbd14/bwMRaTC9WK8urqamxsGi8Rb2tb13fZYDA0eV5lZSUAxcXFLF68mNjYWABGjRrFqFGj+Pe//31NRXlz/Xvamre3syr3/S1vnOkaeBu/U8aTkn+cDSe3sv3sLn7N3E5X92DGjB/IgV0+LNt0koJyI09O6o3OpvXn6LWUfFgKycdFkgvLkF50lvlHlxLl3Y3HBt6LtczVzQOeE8k15LD4+Ep6BHVF73X1kw0I0RbW7FhfX5BfYDKbWHJ8JSbrarQaLVqNFqvz/637o6nbprWq//+m/2iaPKapa2lbepxG26aNfptPJ7Hw6HKMtXUTBxQZill4dDkuLvYMCUlos/u2lGpFuZ2dHSaTqdH2C8X4heL8ty5sDwoKqi/IAXQ6HaNHj2bu3LlUVFQ06hZzJTf6QM+r4a3xZ0r4RG4PvpWknL1szdrJF/sWobO1oVtiOJsOFHPmgxKenBCLq+OVVw9t8X0tNB9qkXxcJLmwDOWmCmbt+hgHawemRfyOooJKtUOyGPd1n8ybxbN5a/N/ebHf07jayodIoa6qmmrOVRY2ua/SVMWCA9+2c0Qto0HTqFDXUlesN/hQcP44zfkCv34/vy3yLx57vDit0fgPY62Rr/euINIhql1e3+UGeqpWlHt7ezfZRSU/v67fso+PT5Pnubm5odPp8PJqvFqcl5cXiqJQXl5+1UW5aMzBxoFhXQYxNGggp8vOsjUzieS8fdj1NJJVdYi/rkrhj0PHog/wVjtUIUQbqzXX8sWhBZQYSvmf+D/gopOi81KONg48GjOdt5M/ZM6heTwV9wjWWtXeYkUnpSgKp0pPszUriT25+5s9zt3Wjb8MeI5axYyimDErCmbMmJULfxTMF/ahXLK9bp+CmVqzGYWLx9b/4ZJzL913/lhFMV+8b/21FcxKbf3+pu5pxnzJuUqj+zV3z1pzTf325gZkFxmK2+qf5Kqo9hsjMjKSefPmNWrV3r9/f/3+pmi1WqKiosjNzW20LycnBysrK1xdZWqq1qTRaAh1CSbUJZi7u49nd+5+Np7eTo79Id47coRuZyIYH3ET3d26Sl9zIW5Qq0/+QGrRce6LnESYa7Da4VikQCd/7ouaxBeHF7Ds+HdMjrhT7ZBEJ1FurCApZzdbs3eRU5GLrZWOfn5xuNm6sv70Lw26sNhobbg9fAw6q9b7prujeGXrP5oswN1t3VSIpjHVivIxY8bw+eefs2TJkvp5yo1GI8uXLyc+Pr5+EGhWVhZVVVWEh4c3OPfNN99k69atDBo0CIDy8nLWrl1LXFwcdnbNLykvro+dtR2DAvszKLA/R3LT+XzHek6Yj/P+3hS87T0ZGJDAAP++0oomxA1kd+4+fjzzC0MCExkY0E/tcCxaX9/enCnNYMPZXwl2DiRR8iXaiFkxc6wojW1ZSezPP0SNUkuYSzD3RU4k3icWO+u67r5e9p4WO7Cxvd0ePqbBwFe4+CHFEqi2eBDA008/zYYNG5g+fTrBwcGsWLGCQ4cO8dVXX9GnT91UfFOnTiUpKYmjR4/Wn1dVVcWECRPIzc1lxowZuLi4sGzZMk6dOtXg3KshfcqvjcFUy2drDrIv/yAeoXmUW+Wi1WiJ8erBwIAEojz0LV7h70bIR2uSfFwkuVBPZnk2byd/SJBzIE9Ll4wWqTXX8uH+OZwsSefZ+D902ikjRdsoNpTUzZaWtYuC6kIcrR1I8ItnYEACAU5+aodn8dSefeVyfcpVLcoNBgPvvfceq1evpqSkhIiICJ599lkGDhxYf0xTRTnU9T2fNWsWmzZtorq6mp49e/Lss8/Sr9+1tUpIUX7tFEVh1dZ0Vm45RWioBn1sGXvP7aXcVIG7rRuJAf0Y6N8Pd7vLfz10o+SjtUg+LpJcqKPCVMmsXbMxmWtk8OJVurDaqaIovNjvqU63uJJoXU2tyq0/vyp3rFdPbKwaz2YnLJPFFuWWRIry65eUksucNSm4Oup4fEJPCjSn2Zq5k9Si42jQ0MMzgkEBCfTyjMKqiWnUbrR8XC/Jx0WSi/ZnVsx8tP9zjhWl8Uz8Y4S5hqgdUodzpiyDd3Z/RKhLME/2frjJ33tCXE5+ZQHbspPYmZ1MibEMV50zA/z7kejfD28HT7XDE9dAivIWkKK8dZzKLmX2sgNUG2t57PaexHbz4lxVIduzd7E9axclxlJcdM4M8O/LQP8EvB08679KKjYU49bJ+7td6kZ8Pq6V5KL9rUxby/rTP3NvxN2yIM512Jm9m7kp3zC8y2Amdr9d7XBEB2CqNbE//xBbs3dxrOgEGjT08opkoH8CPT0j5cNdBydFeQtIUd56isoMzF56gDO5Zdwzohu39OuCRqOh1lzLkcKjbM3ayaFzdV+/+dn7kF9dQK1SW3++jdaGeyPv7vSF+Y36fFwLyUX72pN3gDmHvmZwQH9+F3m32uF0eEuPreLnjC1M7zGl0/9eE83LKs9hW1YSSTl7qKipxNPOg4EB/Rjg3xc3W5lV7kZhkfOUixuXu7MtM++L57M1R/hm4wmyzlUwdXQE1lZWRHv1INqrR/1AlTUnf8SMucH5JrOJVWnr5M1LCBVklecwL2UxYS4hTNTfoXY4N4S7uo0jozyLBalL8Xf0pYtzoNohCQtRXWNgT95+tmUlcar0DNYaK2K9ezEwIAG9e3iLJ0oQNwZpKT9PWspbn1lR+HbzKb7blo6+ixuP39ULZ4eG86I+vvGFZs+fPeyfnfpruhv9+bgakov2UWmq5M3kDzDWGnmx31PSOteKSo1lvLlrNlqNlhf7PoWTTha466wUReF02Vm2ZSWRnLsPQ60RP0dfBvn3I8GvjzwbNzjpvtICUpS3nR2Hc/j8+1TcnXU8NTGWQK+Lv3Cam8gfwM3WlUEBCQwMSOiUxUFneT5aQnLR9syKmY8PfMHRwhP8T/yjdHUNVTukG87p0rO8s+djwl1DeTz2wU7d6NAZVZgq2ZWzl61ZO8mqyEGntSHeN5ZBAf0JcwmWxfc6icsV5Vavvfbaa+0bjmWqqjLS3h9PHB1tqaw0tu9NVRDk40SPMHe2Hcpl075Mgn2d8XV3AMBJ58iRgqOYlYtdWGy0NgwNHIRGA9uyd/FLxlayyrNx0jniYefeaX5xdZbnoyUkF21v9ckf2JGdzOSIu+jt3UvtcG5IbrauuOlc+DljCyZzDVEeerVDEm1MURSOF6ex6uQ65qcu5VBBCu52btwadjNTe0ymj28s7nZuneZ9TdStku7g0PRqqtKnXLSL8ABXXp3Wl9nLDvDekv1MGdmdm/sE1fcbb272lbzKc2zJ2sGOrGT25h/E18GHIYED6O/XBwcbezVfkhA3jL15B/nh9EYG+icwOEBmWmlLiQH9OFOWwU9nNhHsHEgf395qhyTaQImhjJ3ZyWzLTiK/qgB7a3sGBSSQ6J9AF+cAtcMTFkq6r5wn3VfaR7Wxhk9XH2Hv8XMM6x3AvaP0WFvVDWS5XD6MtSb25O1nc+YO0kvPoNPa0Nc3jpuCEm/YQVOd8flojuSi7WSV5/DW7g8JcPTjf+Ifw0ZW7GxzNeYa3t/7CRllmTzX9wkCnfzVDkm0ArNi5kjBUbZlJXGwIAWzYqa7W1cGBiTQ2zsanSzwI5A+5S0iRXn7MSsKK349yZrtp4kKcadvpA/fb0+nsNSAh4stE4aGk9iz+aWCz5RmsDlzO7ty92EymwhzCWZIYCLxPjE31KpmnfX5aIrkom1Umqp4K/kDqmqrmdnv6U45dkMtJYYy3tz1HjZaG17o9xSONg5qhySuUcGFtTiykyk2lOBs48QA/74kBvTD18Fb7fCEhZGivAWkKG9/2w5lM2dNSqO+/DprLdPHRl62MIe6gmJnzm42Z24ntzIfRxsHBvj3ZUhA4g2x0llnfz4uJblofWbFzH8OfElK4TGejnuUbm5haofU6ZwsOc17e/6D3j2cP8Y+INPfdSAmcw0Hzx1hW1YSqYXHAYjy1DPIP4Forx4yiFc0S4ryFpCiXB3/88EWSisaD+DzdLHlrT8OatE1FEXhWFEav2Zu58C5w5gVM1Eeem4KTKSXV1SHfaOT5+MiyUXr++7kD6xN38Bk/V3cFJSodjid1pbMHSw8upxbQoZzR/hYtcMRV5BTkcvW8wv8lJsqcLd1q1/gx8POXe3wRAcgiwcJi9VUQQ5QUGpo8TU0Gg0RHt2I8OhGsaGErVlJbM3cyX8PfoW7rRuDA/szMCABF51za4UtRIe2L/8Qa9M3kOjfjyGBA9QOp1MbHDiAM2UZrD/9M8HOQcT5RKsdkvgNQ62RPXkH2JaVxMmSdLQaLbFePRkYkECkR/cO2/AjLI8U5UJVni62TRbgTvY2KIpy1dNEudm6Mi5sFGNCRnDw3BF+zdzO6pM/8P2pn+jt3YshgYl0cwuT6adEp5VTkcvcI4sIcenCZP2d8rNgASbp7ySzPIe5Kd/g6+BNgNPlu+6J9nGmLIOtWUkk5+yjurYaXwdv7uo2jv5+fXDWNd3SKcT1kO4r50n3FXVsP5zDV2tTMdZcnKdcAyhA725eTB0dgbuz7XXdI7cij81ZO9iRvZuqmir8HX0ZEphIgl889tZ21/cC2pA8HxdJLlpHVU0Vs5I/oMpUzYv9nsLdzk3tkMR5xYYS/m/X+9hb2fF83ydlyleVVJqqSM7dy7asJM6WZ2GjtSbeJ5aBAQmEu4bKh1hx3aRPeQtIUa6e7YdzWL4prX72lTtv6kpZhYlvN5/EykrDxGHdGNo7AO11/jI01hpJzt3P5sxtnCnLRGelI8E3jiGBiQRZ4Lyx8nxcJLm4fmbFzH8PfMWRwqM81fsRurt3VTsk8Rsnik/x/t7/0sNDz6MxM6RbRDtRFIW0knS2ZSWxJ+8AJrOJIKcABgUk0Nc3Tj4giVYlRXkLSFGuvt/mI6+okq/WHSXldBH6IFemj43E39OxVe51uvQsv2ZsZ3fePkzmGrq6hjIkcABxPjEWM0+zPB8XSS6u35qT6/k+/Scm6e9gWFDLBlGL9rcpYxuLj33L2NCbGd/1FrXDuaGVGcvZmbObbVlJ5FbmY2dlR1+/3gwKSCDYOUjt8MQNSoryFpCiXH1N5UNRFLYczOabDScw1tRy26AwxvYPrl9w6HpVmCrZkZ3M5szt5FcV4GTjSKJ/PwYHDsDL3qNV7nGt5Pm4SHJxfQ7kH+a/B79igF9ffh81Sb6Ct2CKovB1yhJ25CTzSPR0Yr17qh3SDcWsmEktPM7WrKT62bq6uoYyKCCBOJ8YbK2aXv5ciNYiRXkLSFGuvsvlo6TcwPyfjpOcmkeQtyP33xpFmL9Lq93brJg5WnSCzRnbOXDuCAA9PSMYEphID88IVb5GlufjIsnFtcupyOOt5A/wcfDm2fg/3FALbN2oTLUm3tnzMXmV+Tzf90n8HH3UDqnDScrZw6q0dRQZinG3dWNk8E1U1lSxPWsXRYZinGwc6e/Xh4EB/fBz9FU7XNGJSFHeAlKUq68l+dh7LJ95649SUmFkVN8u3DWkK7a61l2koai6mK1ZO9malUSpsQxPO3cGBwwgMaBfu464l+fjIsnFtamqqeat5A+oMFUys9/TMrCzAymqLub/dr2Po40jz/d9wqIHpVuapJw9LEhdhslsarQv0r07gwL7E+3Vw2K6KorO5XJFudVrr732WvuGY5mqqoyNVpZsa46OtlRWNj1Pd2fUknz4ezoyJCaASkMNG3ZnsPNILv5eDvi4t94S1fbWdujduzE8aDABTv7kVZ5jW/Yufjm7hdzKfJx1zrjburZ5FwB5Pi6SXFw9s2Lmi8MLSC89wx9i7ifQAgczi+bZW9sR4tKFnzO2kFORS5xPjHQ7ugxFUSg2lHC08DgLUpdhNDf+feGqc+HP/Z/B39EXKxlEK1Si0WhwcGi6m5R8TBQdjoOdNdNGRzCghy9frE3lnW/2M7CXH1NGdsfJvvW+mrfSWhHvE0O8TwzZFblsztzBzuzd7MrdS6CTP0MCB9DPNw47acESFuiH9I0cOHeYid1vp7t7uNrhiGugdw/nrm7jWHZ8NT+k/8zYsJFqh2QxKkyVnCnNIL30LKfLznK69Cylxst/m1ZiLG2n6IS4NtJ95TzpvqK+a8mHqaaW1dvSWbvjDA521tx7s56EKJ82a1GqrjGwO3cfv2ZuJ6M8CzsrWxL8+jAkcECrL/ghz8dFkourc/DcEf574Cv6+cUxLWqytLB2YIqi8NWRRSTn7uOxmBn08opSO6R2Z6w1kVGeWVeAn/+TX1VQv9/XwYdQly4EuwQR6tKFzw5+TZGhuNF13G3d+N9Bf27P0IVoRPqUt4AU5eq7nnycyS3jy7WppOeUERvuydTREXi4tF0LtqIopJee4dfM7ezJ3U+NUks3tzCGBCbS27sX1q3QV1Gej4skFy2XW5nPrF0f4O3gybPxf0QnAzs7PGOtkX/t/oiC6kJe6PskPg7eaofUZmrNteRU5pFeeobTpRmcLj1LVkUOZqVugTk3W1dCXboQ4tyFEJcuBLsEYm/dcB7xpvqU22htuDfybhL84tv19QjxW1KUt4AU5eq73nyYzQo/JZ9l+eaTaDQaJg4NZ3h84HUvOnQl5cYKtmfvYnPmDgqqC3G2cWJgQAKDA/vjYed+zdeV5+MiyUXLVNdU81byh5SbKnih71N42l/78ycsS0FVIW/umo2LrTPP9XkCO+vrW+nYEiiKQkF1YYMW8LNlmRjPF9P21vbnC/AgQlzqinBX25bNuvXb2VduDx8jBbmwCFKUt4AU5eprrXzkF1cxd10qh9OL6BboyoyxkQR4tc6iQ5djVsykFB5nc+Y2Dp1LBaCXVxRDAhOJ8uh+1dMqyvNxkeTiysyKmc8Ofc3Bc0d4svdD6N27qR2SaGWphcf5cN9n9PbuxYO9ft/huiWVGsvOF991LeCny85SYaoEwEZrTRfnwPoW8BCXILztvTrcaxTiSqQobwEpytXXmvlQFIVth3JYtOE4BlMt4xNDuTUxpNUWHbqSgqoitmbtZFtWEmWmcrzsPRkc0J9E/3446Vr2AUGej4skF1e2Ln0Dq0/+wN3dxjMi+Ca1wxFt5Kczm1hxYg13hI/llpDhaofTrOqaas6UZda3gKeXnq3v561BQ4CTX4MW8ABHP6y0rTu9rRCWSIryFpCiXH1tkY+SCiMLfzpGUkoegV6OzBgbSXiga6ve43JqzDXsyz/ErxnbSSs5hbXWmj4+sQwJHECoS/BlW4Hk+bhIcnF5h86l8J8DX9LXtzfTe0yR1sUbmKIofHF4AXvyDvDH2Afo4RmhdkjUmGvILM+ubwFPLztLbkUeCnXvqZ52HnXdUM7/6eIcKCtnik5LivIWkKJcfW2Zj30nzjHvh6MUlxkY2SeICUO7Yqdr3xlBs8pz2Jy5nZ05uzHUGuniFMCQoET6+sY1+QYlz8dFkovm5VXmMyv5AzztPPhTnz+ik2LnhmeoNfJ28ocUG0p4sd9TeNl7ttu9zYqZvMpz9d1P0kvPklmWRY1SC4CTjWODAjzEuUuLvx0UojOQorwFpChXX1vno8pQw7JNaWzck4mniy3TxkQS3bX93swuqK6pZlfuXn7N2E5WRQ721nb0Pz+top+jb/0ApWJDMW4yQAmQn5XmVNdU89buf1NmLOPFvk/hae+hdkiineRXFvBm8mw87Nz4U5/H26Tl+cKCPKfLMuq7oZwuzaC6thoAnZWuQReUEOcueNi5yTc1QlyGFOUtIEW5+torH8czivlybSrZBZUM6OnL70Z2x7mZ1bXakqIopJWkszlzO3vzDlKr1OJn70N+dQG151udQKbyAvlZaYqiKHx26Gv25x/iid4PEenRXe2QRDs7XHCUj/d/Th/fWGb0+N11F8OVpspLCvAMTpeeoeT8gjxajZYgJ39CXILrC3E/R5+rHsAuRGcnRXkLSFGuvvbMh6nGzJrt6azZfhp7W2t+d3N3BvTwVa2Fp8xYzvasXaw++QNmzI32d/ZFL+RnpbEf0jey6uQ67uo2jpuDh6odjlDJhedgQrfxjLyKAb51C/JkXdICfpa8qnP1+30dvOtbv0NcuhDk5I+NzHkvxHWTorwFpChXnxr5yMgv58u1qZzMKiW6qydTR+vxcrW/8olt5PGNLzS7b1zYKKI89AQ7B3W6WQrkZ6XOpXMvA4S5BPOnPo9Ld4FO7MI3JvvyD+Js40SZqbzRvNxmxUx2RW6DAjzzNwvyhFwyH3iwcxAONur9HhTiRiZFeQtIUa4+tfJhNits2JPB8k0nAZgwtCsj44PQatu/0Hll6z+aXB7aSmOFWTGjoGBvbU+EezeiPLoT5aHvFP2I5WdFVikUzduauZMFR5c12GalsSLCvRuGWiNnyzIuWZDH7pK5wOvmA3ezbb8ZqYTo7C5XlLfv9BNCWCCtVsOovl2I6+bF3B+OsvCn4yQdyWXG2EgCvZv+wWkrt4ePabbw6uERwdGi46QUHiel8Bj78g8C4GPvRaSHniiP7ujdw7GztmvXmEXbqq6pJr30LN8c/bbBcwFgMptYlbZOivJObm36hkbbapVajhQeJcwlmIEBCfVFuLe9p/QDF8JCqdpSbjQaef/991m5ciWlpaVERkbyzDPPkJiYeNnzPvjgAz788MNG2728vNi6des1xSIt5eqzhHwoisKOI7ks/Ok4VYYaxiWGMC4xFBvr9nsTa8nsK4qikFuZV1+gHy9Kw2g2odVoCXMJoYennigPPV2cA2+IN2BLeDbaS7GhhLTidE6WpJNWkk5GWVb9fM/N+feIWe0UnbBEl+v2Js+GEJbFYlvKZ86cyfr165k2bRohISGsWLGChx9+mHnz5hEXF3fF89944w3s7C62Cl76/0JcC41GQ2JPP3qGebBow3FWbU1nV2oe94+NoltQ+3zFm+AXT4Jf/GULUY1Gg5+jL36OvgzvMhiTuYZTJen1Rfrqkz+w+uQPOFo7EOHRjSgPPZEe3fGwc2+X1yBaxqyYyanII60kvb4QL6guBECntSHUJZgxoSMIdw3j69QlFBtKGl3D3datvcMWFsbd1q3Jbm/ybAjRsajWUn7gwAEmTZrESy+9xIwZMwAwGAyMHz8eHx8f5s+f3+y5F1rKd+3ahYuLS6vEIy3l6rPEfBxIO8fcH45SVGpgeHwgdw8Nx962fT7LXk8+yozlHC282NWlxFgKgK+DT31f9G5uXbGztm3NkNuMJT4b18JUa+J0WQYni9NJKznFyZLTVNZUAeCscyLcNYxw1xDC3cIIcgpoMKBX+pSL5sizIUTHYZEt5evWrcPGxoZJkybVb7O1tWXixIm8++675OXl4ePjc9lrKIpCeXk5jo6OMvuAaBMx4V787UE3Vvx6kg27M9h7/BzTRkcQ281L7dAuy1nnRF+/OPr6xaEoCtkVuaQWHuNI4TG2Zu3kl4ytWGms6OoaQpRHXVeXIOeAG6KriyUpN1bUd0M5WZLOmdKM+pUPfR186O0dTbhbKF1dQ/G297zs77ELxdWF2Vd+O8OG6Lzk2RDixqBaUZ6SkkJYWBiOjg2X342JiUFRFFJSUq5YlA8bNozKykocHR0ZPXo0L774Im5u8nWdaF32ttbcO0pPQg9fvlybyvtLD5AQ5cO9N+txcbT8Jc01Gg0BTn4EOPkxIvgmTLUm0krSSSk8RkrhMVadXMeqk+twsnE8P6uLnihPvczIcJUUReFcVSFpJafqu6LkVOYBdTNhBDsHMazLYMJd64rwa1l6/ELXJiF+S54NITo+1Yry/Px8fH19G2339vYGIC8vr9lzXVxcmDp1KrGxsdjY2LBjxw6++eYbjhw5wpIlS9DpLL9QEh1Pt0BXXru/H2u2n+a7bekcPlXIlJHdGdjLr0N9U2NjZUOkR3ciPbpzF+MoGjrW5wAAIABJREFUMZSdn9WlrkjfnbcfAH9H3/N90fV0dwtD1wbLeHdkteZaMsqz6vuDp5WcosxYDoC9tT3hriEk+MUT7hZGsHMQOll4RQghxGWoVpRXV1djY9P4TcrWtq6Pq8FgaPbc6dOnN/j7mDFj6N69O2+88Qbffvst99xzz1XH01z/nrbm7e2syn0tVUfIx0N3xXBLYigfLN7HnDUp7Dl+jj9OjMXP8+pbPq+kPfLhjTPdggIYx1AUReFMSSb7c1I4kJPC5sztbDy7GWutNVHe4cT49iDWL4pgt/af1UXtZ6PSVMXxglOk5qeReu4EJwrSMdQa62Jz9KS3fw8ivboR6R1OoIufdAUSQghxVVQb6Dl+/Hh8fX2ZM2dOg+0nTpxg3Lhx/O///m+D/uZXYjabiY+PZ/jw4bz77rtXHY8M9FRfR8uHWVH4eU8mSzeloSgKE4Z05ea+XVpt0SFLyIex1kRa8an6VvSsihwAnG2ciDw/YDTSozuutq0z4Lo5auSiqLq4vj94WnE6meXZKCho0BDkHEBX11DCXUMJdwuVrj5CCCFaxCIHenp7ezfZRSU/Px/giv3Jf0ur1eLr60tJSeMpw4RoC1qNhpF9gujdzYt564+yaOMJdqbkMmNsFF181PnmpbXprGyI8qzrYw51c2gfLTxRX6Tvyt0LQICjX/2A0XC3sA7XVePCMuSXzg9eWF0EgM5KR5hLMGNDR9LVLZQwl2BZoEkIIUSrU60oj4yMZN68eVRUVDQY7Ll///76/VfDZDKRnZ1Nr169WjVOIa7E09WOpyfGsDMllwU/HueNL3cxdkAwtw0Mxcba6soX6EDcbF3p79+H/v59MCtmMsuzzxfox9mUsZUNZ3/FRmtNN7eu9S3pAY6W1+feWGvidOnZulbwklOcKjlD1fmpCV10zoS7hjKiyxDCXUMJdPJvMDWhEEII0RZUK8rHjBnD559/zpIlS+rnKTcajSxfvpz4+Pj6QaBZWVlUVVURHh5ef25hYSEeHh4NrjdnzhwMBgNDhgxpt9cgxAUajYYBPfzoGerBNxtP8N220ySn5jNjbCT6LjfmjEBajZYuzoF0cQ7klpDhGGqNnCg+WV+krzixhhWswUXnXN/NJdKjOy66/2fvzuOirvM/gL/mYrhhgOGQW1AuAQWPTEvNC68yw2qztLKyMi3dfpnbse2W2apbdrdqtWq25QGi5W1qWgYKJh4cgggiIMN9KDDDzO8PcGjikFHgC8Pr+Xj02Phe857PErznw/vz/nR9bXhlXVVTa8KyS8ipvIL6xtaErlYuiHAO05eiOJo7dLsPEUREZPoEqykHgBdffBEHDx7EnDlz4OXlhdjYWJw9exbr169HZGQkAOCxxx5DQkIC0tLS9PeFh4dj8uTJ6N+/P8zMzBAfH4+9e/ciMjISGzZsgFRq/GcN1pQLz5TG4+zFYqzfk4biihqMHuSOmaON33Sop49HaU0ZUhs3L0otvYBq9TUAgId1H32S7mfnA1k7Sl2MGQudTgfV9aLGjigN5ShXrzWUxUlFEnjZeuoTcF87b1jLOn6BLhERUUvaqikXNCmvra3F6tWrsXPnTpSXlyMgIACLFy/GnXfeqb+mpaT89ddfR1JSEvLz86FWq+Hu7o7Jkydj3rx5MDe/tVpPJuXCM7XxqKnTIPbnLBw4eRn2NnI8OqE/BvVTtvt+UxoPrU6L3Mo8fS36xfJs1OvqIRPL0M++b8Muo44BcLV0NpilTihIwo7MPSirLYN9KxuiaLQaXK7MM5gJr1Q3tCa0klqir71346JMX3jZuLfrQwAREVFn6LZJeXfCpFx4pjoemXnl+O/uVFxRVWNIoDMeGd8fdu3YdMhUxwMAajS1BqUuVxs32bGX2+lr0a+paxCTsbPZ1uHR/aZBYa7AxbIsZJZfwqWKy/prnMwd4Gfv27BBj70PXCyVbE1IRETdBpPydmBSLjxTHg9NvRa743Ow85csyGUSPHiPP0aGurVZu2zK4/FnJTWlSC25gPMl6UgruYBrjYsu2yIWieFh3UefgPvZ+XR6a0YiIqLbwaS8HZiUC683jEd+cTX+uzsVF3LLEeStwJxJgXC2t2jx2t4wHi3R6rTIqczFypOftHrNgoFPw8fWC+ZSeRdGRkREdHvaSsr5d12iLuTmaIUlsyLw2IT+yMqvwJvr4rEnPgf1Wq3QoXUbYpEYPrZeUMhb7lqjkNsj0KEfE3IiIjIpTMqJuphYJMKYCA+889QwBPs4YPOhDLyzIRE5V3vfrHhb7vWLgkxsuChTJpbhXr8ogSIiIiLqPCxfacTyFeH1xvHQ6XQ4kVqIb/eno+q6BlHDvODiYIEdx7JQUlELB1s5Zozyw/AQV6FDFUR7uq8QERH1FKwpbwcm5cLrzeNRdV2N73+6gF/OFDQ7ZyYVY86kwF6bmAO9+3uDiIhMB2vKibo5awsZ5k4Jho1l8x7adRotYo5kChAVERERdRUm5UTdSOU1dYvHiytquzgSIiIi6kpMyom6EUfbljuKKGzYaYSIiMiUMSkn6kZmjPKDmbT5f5Z16nrkqqoEiIiIiIi6ApNyom5keIgr5kwKhKOtHCI0zJxPv8sXUqkY725MxNmLxUKHSERERJ2A3VcasfuK8Dgehv44HiUVNfhwazKuqKoxa3w/jInwEDi6rsXvDSIiMgXsvkLUwznYmuPVWREY0NcBG/el49sD6V3+IZKIiIg6D5Nyoh7CQi7FwgfCMH6wJw6czMXH25JxvVYjdFhERETUAZiUE/UgYrEIfxnXD49O6I8zF0vw3qYklFTUCB0WERER3SYm5UQ90D0RHnhxZhhUZdfx9oaTuFRQIXRIREREdBuYlBP1UKF9HfG3xyIhFYvx3jdJSExTCR0SERER3SIm5UQ9mIfSGq/PGQwPZ2t8FnsGu+OzwYZKREREPQ+TcqIezs7KDK/8ZRAGBzpjy6FMrN+TCk29VuiwiIiIyAhSoQMgottnJpNg3n0hcHGwxA+/XoKqrAbP3z8AVuYyoUMjIiKiduBMOZGJEItEmHF3X8ydEoT0y2VYtiERhaXXhA6LiIiI2oFJOZGJGRHqhpcfHojKa3V4Z0Mi0i+XCR0SERER3QSTciITFOClwOuzB8PKQoZV353C8bMFQodEREREbWBSTmSiXBws8dpjkfB3t8PaH85j+9GL7MxCRETUTTEpJzJh1hYyLH5oIEaGumHHL5ewZud5qDX1QodFREREf8LuK0QmTioR44nJgXBxsMC2IxdRVH4dC2aEwdbKTOjQiIiIqBFnyol6AZFIhCnDffD89AHIuVqFdzacxJWiaqHDIiIiokZMyol6kcGBzljySATqNFq8u/EkzmWVCB0SERERgUk5Ua/Tt48t3pg9GI625vhg82kcPnVF6JCIiIh6PSblRL2Qo505lj4aiRBfB2zYm4bvDl6AVsvOLEREREJhUk7US1nIpVgYHYqxkR7Yd+IyPok5g5o6jdBhERER9UpMyol6MYlYjFnj+2PW+P44nVmE975JQklFjdBhERER9TpMyokIYyM98GJ0GK6WXcc7G04iu6BS6JCIiIh6lQ5JyjUaDfbu3YvNmzdDpVJ1xCOJqIuF+Tnhb49GQiwWYfmmRJxK53/LREREXcXopHzFihV44IEH9F/rdDo88cQTeOmll/Dmm29i2rRpyMnJadez6urqsHLlSowcORJhYWF48MEHcfz4cWNDwtNPP42AgAAsW7bM6HuJqImnszXemD0Y7k5W+CTmDPbE50Cn4wJQIiKizmZ0Un706FEMHjxY//VPP/2EEydOYO7cufj3v/8NAFizZk27nvXqq69i/fr1uPfee/Haa69BLBbj6aefxqlTp9odz+HDh3Hy5Enj3gQRtcrOWo5XHolAZIASmw9lYMPeNGjqtUKHRUREZNKMTsoLCgrg7e2t//rQoUPw8PDAyy+/jClTpuDhhx9u12x3cnIyfvzxR7z88st45ZVX8NBDD2H9+vVwc3PDqlWr2hVLXV0dli9fjrlz5xr7NoioDXKZBM9OH4Apw71x5Pc8rN5yGtdq1EKHRUREZLKMTsrVajWkUqn+6/j4eNx55536rz09PdtVV75nzx7IZDLMnDlTf0wulyM6OhqJiYkoLCy86TM2bNiAmpoaJuVEnUAsEuGBUX54YnIg0nLKsGxjIgrLrgsdFhERkUkyOil3dXXVl5dcuHABly9fxpAhQ/Tni4uLYWlpedPnpKSkwNfXF1ZWVgbHw8LCoNPpkJKS0ub9KpUKn332GRYtWgQLCwtj3wYRtdNdYX3w14cGoqK6Du+sP4mM3HKhQyIiIjI5RiflU6ZMwfbt2zFv3jzMmzcP1tbWGDVqlP58SkoKvLy8bvoclUoFZ2fnZseVSiUA3HSm/P3334evry/uu+8+I98BERkr0FuB12YPhqW5FCv+dwq/nS8QOiQiIiKTIr35JYbmzZuH/Px8HDx4ENbW1vjXv/4FW1tbAEBlZSV++uknPP744zd9Tk1NDWQyWbPjcrkcAFBbW9vqvcnJydi+fTs2btwIkUhk7FtokaOjdYc8x1hKpY0gr9tdcTwMdafxUCpt8MGi0Xj3vwlYs+M8qmrq8fCEgA77b7A9r09ERGSqjE7KzczM8O6777Z4zsrKCseOHYO5uflNn2Nubg61uvnCsRvJ+I3k/M90Oh2WLVuGCRMmGHSBuV3FxVXQaru29ZtSaQOVipu03MDxMNRdx2PhjFBs2JOKb/el4eKVMjwxKRAyqaRTX7O7jgUREZExxGJRqxPBRiflbdFoNLCxad9sllKpbLFE5cYi0ZZKWwBg//79SE5OxqJFi5Cbm2twrqqqCrm5uXBycmrXBwMiMp5MKsaTU4Lg4mCJmJ8voqi8Bi/MCIWtpZnQoREREfVYRteUHzlyBB9//LHBsU2bNiEiIgIDBw7EX//61xZnwP8sMDAQWVlZqK6uNjh++vRp/fmW5OXlQavVYs6cORg7dqz+HwCIiYnB2LFjkZCQYOzbIiIjiEQiTL3TB8/eF4JL+ZVYtuEk8ourb34jERERtcjomfIvv/wSjo6O+q8zMzPx7rvvwtPTEx4eHti1axdCQ0NvWlceFRWFr776Clu2bNFfW1dXh5iYGERERMDFxQVAQxJ+/fp1+Pn5AQDuueceeHh4NHve/PnzMWbMGERHRyMkJMTYt0VEt2BokAscbc3x8bZkvLMhEfPvH4BgHwehwyIiIupxjE7KL168aNBtZdeuXZDL5di6dSusra3x17/+Fdu3b79pUh4eHo6oqCisWrUKKpUKXl5eiI2NRV5eHpYvX66/bsmSJUhISEBaWhoAwMvLq9XuLp6enhg3bpyxb4mIboOfux1enz0YH25NxgebT+PRCf0xaqC70GERERH1KEaXr5SXl0OhUOi//vXXX3HHHXfA2rqhaH3o0KHNar1bs2LFCjz22GOIi4vDO++8A41GgzVr1iAyMtLYsIhIQE72Flj6aCQCvRVYvycNmw9lQKvr2oXTREREPZnRM+UKhQJ5eXkAGhZWnjlzBosXL9af12g0qK+vb9ez5HI5lixZgiVLlrR6zcaNG9v1rBsz6UQkDEtzKV6aGYZv91/AnvgcXC25hmemhUBu1rmdWYiIiEyB0Un5wIED8d1338Hf3x8///wz6uvrcffdd+vPZ2dnt9o5hYhMm0QsxqMT+sPVwRLfHbyA9zYlYWF0GBQ2Lbc4JSIiogZGl68sXLgQWq0WL730EmJiYjB9+nT4+/sDaOghfuDAAURERHR4oETUM4hEIowf4okFD4ShoOQa3tlwEjlX2WOciIioLSKdzvjCz7KyMiQlJcHGxgZDhgzRHy8vL8f27dsxbNiwVlsadlfcPEh4HA9DpjAeOVcr8eHWZFyr0WDevSEY2M/plp5jCmNBRETU1uZBt5SUmyIm5cLjeBgylfEorazFR9uSkVNQiYfG9sP4wR4QiURGPcNUxoKIiHq3TtnRMycnBwcPHsTly5cBNLQjHDt2bKvtComod1LYyPHqIxFYs/Mcvjt4AVdLruGR8f0gERtdPUdERGSybikpX716NdauXdusy8rKlSsxb948vPjiix0SHBGZBrmZBPNnhGLb4Uzsjs9BYdl1PHffAFia3/K8ABERkUkx+jfi1q1b8cUXX2DQoEF46qmn0K9fPwDAhQsX8OWXX+KLL76Ap6cnZsyY0eHBElHPJRaJMHOMP1wcLLFxbxre/SYRL0WHwcneQujQiIiIBGd0TfmMGTMgk8mwadMmSKWGOb1Go8GsWbOgVqsRExPToYF2NtaUC4/jYciUx+P8pRJ8GnsWMokICx4Ig5+7XZvXm/JYEBFR79FWTbnRRZ2ZmZmYPHlys4QcAKRSKSZPnozMzEzjoySiXiPYxwGvz46E3EyCf317CgkpV4UOiYiISFBGJ+UymQzXrl1r9Xx1dTVkMtltBUVEps/N0Qqvzx4MHzcbfBF3Djt/yQKbQRERUW9ldFIeGhqK77//HkVFRc3OFRcXY/PmzQgPD++Q4IjItNlYmuH/Hh6EO0JcEHs0C+t+SIFaoxU6LCIioi5n9ELP559/Ho8//jgmT56MBx54QL+bZ0ZGBmJiYlBdXY1Vq1Z1eKBEZJpkUjGenhoMV4Ulth/LQnH5dcyfEQobSzOhQyMiIuoyt7R50E8//YS3334b+fn5Bsf79OmDN998E6NHj+6o+LoMF3oKj+NhqDeOx2/nC/DVj6lwsJHjxZlhcHO0AtA7x4KIiExPp+zoqdVqcfbsWeTm5gJo2DwoJCQEmzdvxoYNG7Br165bj1gATMqFx/Ew1FvHIyO3HB/HJKO+XocxEe747VwBSipq4WArx4xRfhge4ip0iERERLekU3b0FIvFCAsLQ1hYmMHx0tJSZGVl3epjiaiX8/eww+uzB+PdjSfx4/Fs/fHiilqs350KAEzMiYjI5HCfayLqdpT2FhCLm/94qtNoEXOELVeJiMj0MCknom6ptLK2xePFFS0fJyIi6smYlBNRt+RoK2/xuKVc2uXrP4iIiDobk3Ii6pZmjPKDmdTwR5RIBFyr1WD5N4nIL64WKDIiIqKO166Fnl9//XW7H5iUlHTLwRAR3XBjMWfMkUx995X77+4LsUiETfvT8dbXJ/DA3X0xbognxCKRwNESERHdnna1RAwMDDTuoSIRUlJSbjkoIbAlovA4HoY4Hk3+PBZlVQ2dWE5nFqO/hx2enBIEZ4WlgBESERHd3G23RNywYUOHBkREdDvsreVYGB2GX88W4NsDF/DmVwmYOdofYyLcOWtOREQ9UruS8qFDh3Z2HERERhGJRBgR6oYgbwX+uzsVm/anIyldhScmBcLJ3kLo8IiIiIzChZ5E1KM52Jpj0YPhmBMVgIv5FXjjqwQc/v0KbnGzYiIiIkEwKSeiHk8kEmHUQHe8/eRQ+LraYMOeNHyw+TRKKmqEDo2IiKhdmJQTkclwsrfAy38ZhFnj+yM9twxvfJmAY8n5nDUnIqJuj0k5EZkUsUiEsZEe+OeTQ+GptMJXu1Lw0dZklFVxJ1AiIuq+mJQTkUlyVljilVkReHhsP5zPLsUb6+Lx27kCzpoTEVG3xKSciEyWWCTChCGeeOuJIXB1sMSanefxWexZVFTXCR0aERGRASblRGTy3BytsPTRSMwc7YfTmUV4fV08TqYWCh0WERGRHpNyIuoVxGIRJt3hjb8/PgSOdub4bPtZfBF3FlXX1UKHRkRExKSciHoXd6U1XnssEvff5YvENBVeXxePUxdUQodFRES9HJNyIup1pBIxpo3wxRtzBsPOygwfbzuDtTvPo7qGs+ZERCQMJuVE1Gt5udjgjTmDMe1OH8Sfv4o31sUjObNY6LCIiKgXEjQpr6urw8qVKzFy5EiEhYXhwQcfxPHjx296344dOzB79myMGDECAwYMwD333IOlS5fiypUrXRA1EZkSqUSM++/ui9fnRMLKXIbVW07j610puF6rETo0IiLqRUQ6AZv2Ll68GPv27cPs2bPh7e2N2NhYnD17Fhs3bsSgQYNavW/FihVQqVQIDAyEnZ0d8vLysHnzZtTX12PHjh1QKpVGx1JcXAWttmuHQqm0gUpV2aWv2Z1xPAxxPJp01VioNVrEHcvC7vhsKGzkeGJyEEJ8HDr9dYmIqHcQi0VwdLRu8ZxgSXlycjJmzpyJpUuX4vHHHwcA1NbWYurUqXB2dsamTZuMet65c+cwY8YMvPLKK5g7d67R8TApFx7HwxDHo0lXj0XmlXJ8+WMKCkquYcwgd8wc4wdzM2mXvT4REZmmtpJywcpX9uzZA5lMhpkzZ+qPyeVyREdHIzExEYWFxvUQ7tOnDwCgoqKiQ+Mkot7Hz90Obz0xBBOGeOLwqSt488sEpOWUCh0WERGZMMGS8pSUFPj6+sLKysrgeFhYGHQ6HVJSUm76jLKyMhQXF+PMmTNYunQpAGD48OGdEi8R9S5mMgkeHtsPS2ZFQCwS4V/fnsK3B9JRq64XOjQiIjJBgv09VqVSwcXFpdnxG/Xg7ZkpnzhxIsrKygAA9vb2ePPNN3HHHXd0bKBE1Kv197THP54ciq2HM3HgZC7OZBZj7pRg+HvYCR0aERGZEMGS8pqaGshksmbH5XI5gIb68pv55JNPcO3aNWRlZWHHjh2orq6+5Xhaq+/pbEqljSCv211xPAxxPJoIPRYvzYrEPcO88OH3v2P5pkRMH+WPR6MCYSaTCBoXERGZBsGScnNzc6jVzTfquJGM30jO2zJkyBAAwKhRozB27FhMmzYNlpaWePTRR42Ohws9hcfxMMTxaNJdxsLNzhx/nzMYmw9lIPZwBn47k4enpgbD181W6NCIiKgH6JYLPZVKZYslKipVw3bXzs7ORj3P09MTISEh2LlzZ4fER0TUEgu5FHOiArH4oXDU1NVj2YZEbDuSCbVGK3RoRETUgwmWlAcGBiIrK6tZycnp06f1541VU1ODykrhZ9OIyPQN8HXE23OH4s4BrvjxeDbeXn8C2QX8+UNERLdGsKQ8KioKarUaW7Zs0R+rq6tDTEwMIiIi9ItA8/LykJmZaXBvSUlJs+edPXsWqampCAkJ6dzAiYgaWZrL8OSUICyMDkPldTXe2XAScceyoKnnrDkRERlHsJry8PBwREVFYdWqVVCpVPDy8kJsbCzy8vKwfPly/XVLlixBQkIC0tLS9MfGjBmDSZMmoX///rC0tERGRga2bdsGKysrPP/880K8HSLqxQb6O8F/7jB8eyAdcceycOqCCk9NCYaHszALyImIqOcRdIu6FStWYPXq1YiLi0N5eTkCAgKwZs0aREZGtnnfI488guPHj+PAgQOoqamBUqlEVFQUnn/+eXh6enZR9ERETawtZHhmWggi+ztjw95U/OO/JzD9Ll9EDfOCRCzYHyWJiKiHEOl0uq5tOdJNsfuK8DgehjgeTXraWFRcq8M3+9JxMrUQvm62mDslCH2crG5+IxERmbRu2X2FiMhU2Vqa4fnpA/DsfSFQlV3HW1+fwJ74nC7/4E9ERD2HoOUrRESmbGiQCwK8FNiwJxWbD2Ug6YIKcycHwcXBUujQiIiom+FMORFRJ7KzMsMLM0Lx9NRg5Kmq8fevErD/5GVoWTlIRER/wJlyIqJOJhKJMHyAKwK9FVi/JxX/O3ABp9JVeGJyEJT2FkKHR0RE3QBnyomIuojCRo4Xo8PwxORAZF+txJtfJuDQqSvgensiImJSTkTUhUQiEe4K64N/PjkM/u622Lg3Df/+/ncUl9cIHRoREQmISTkRkQAc7cyx+KGBmD0xAJlXKvDmV/E4ejqPs+ZERL0Uk3IiIoGIRCKMHuSOf84dCm8XG3y9OxUfbk1GaWWt0KEREVEXY1JORCQwpb0FXv7LIDwyrh9Ss0vxxrp4HD9bwFlzIqJehEk5EVE3IBaJMG6wJ/4xdyj6KK2w9ofz+CTmDMqr64QOjYiIugCTciKibsRFYYlXH4nAg2P8ceZiCd5YF4+ElKtCh0VERJ2MfcqJiLoZsViEqGFeCPd3xLofUvBF3DmcTFMhyNseu45no7iiFo62cswY5YfhIa5Ch0tERB2ASTkRUTfl5miFvz0WgT3xOYj5+SJOphbqzxVX1GL97lQAYGJORGQCWL5CRNSNScRiTBnuA1tLs2bn6jRaxBzJFCAqIiLqaEzKiYh6gNYWfBZX1LJLCxGRCWBSTkTUAzjayls99/evEnD8bAE09doujIiIiDoSk3Iioh5gxig/mEkNf2SbScUYPbAPdDpg7Q/nsfQ/v+HAycuorasXKEoiIrpVXOhJRNQD3FjMGXMks1n3Fa1Oh+TMYuz+LRvfHriAHb9cwthID4yN9IC1hUzgyImIqD1EOhYjAgCKi6ug1XbtUCiVNlCpKrv0NbszjochjkcTjkX7ZeSWY9dv2fg9owhmMjHuDuuDCUM94WRnIXRoRES9nlgsgqOjdYvnOFNORGRC/D3ssDA6DFeKqrEnPhuHTl3BT0lXMCzYGZOGecPDueVfBkREJCwm5UREJsjdyQpzpwTj/rv6Yt+Jyzjyex6On7uKMD9HTBrmhf6e9hCJREKHSUREjVi+0ojlK8LjeBjieDThWNy+qutqHErKxYHEXFReU8Ovjy0m3eGNgf2cIGZyTkTUJVi+QkTUy1lbyDBthC8mDvXCsTP52BOfg09izsDN0RJRw7wwPMQVUgkbchERCYUz5Y04Uy48jochjkcTjkXHq9dqcTJVhd2/ZSOnsAoKGznGD/bEqIF9YCHnfA0RUWfgTDkRERmQiMUYFuyCoUHOOHepBLt/y8HmQxn44ddLGBPhjnGDPWFnZSZ0mEREvQaTciKiXkwkEmGAryMG+DoiK78Cu37Lxq7j2dibcBkjw9wQNdQTzgpLocMkIjJ5TMqJiAgA4Otmi/n3h6Kg5Br2xOfgWHIejvx+BYMDnDH5Dm8FkOIzAAAgAElEQVR4u9oIHSIRkcliUk5ERAZcHSzx+KRATL/LF/tPXsbhU1dwIrUQwT4KTL7DG0HeCrZTJCLqYFzo2YgLPYXH8TDE8WjCsRDWtRoNjvx+BftOXEZ5dR28XW0waZgXBgc4Qyxmck5E1F5c6ElERLfM0lyKSXd4Y9xgTxw/V4Ddv2Xji7hzcFZcRNRQL4wIdYVMKhE6TCKiHo1JORERtYtMKsbd4X0wMtQNSekq7I7Pxoa9adh+LAvjB3tgzCB3WJrLhA6TiKhHYlJORERGEYtFGBzojMgAJVJzyrD7t2xsO3IRPx7PxuiB7hg/xBMKG7nQYRIR9ShMyomI6JaIRCIEeSsQ5K1AztVK7I7Pwd4TOdh/8jKGD3DFpGFecHO0EjpMIqIegUk5ERHdNi8XG8y7NwQz7u6LvQk5OJqcj1+S8zGwnxMm3+ENP3c7oUMkIurWBE3K6+rq8OGHHyIuLg4VFRUIDAzEokWLMHz48Dbv27dvH3bt2oXk5GQUFxfDzc0NY8aMwfPPPw8bG/bRJSISitLeAo9OCMC9I3xxIDEXh5JycepCEQI87THpDm+E9nVgO0UiohYI2hJx8eLF2LdvH2bPng1vb2/Exsbi7Nmz2LhxIwYNGtTqfcOGDYOzszPGjRuHPn36IC0tDd999x18fHywbds2yOXG1zKyJaLwOB6GOB5NOBY9V02dBj//noe9Jy6jtLIWHkprTLrDC0ODnCERi4UOj4ioS7XVElGwpDw5ORkzZ87E0qVL8fjjjwMAamtrMXXqVDg7O2PTpk2t3hsfH49hw4YZHNu+fTuWLFmC5cuXY8aMGUbHw6RceBwPQxyPJhyLnk9Tr0X8+avYHZ+DvKJqONqaY+JQT9wV3gdyGdspElHv0FZSLtg0xZ49eyCTyTBz5kz9MblcjujoaCQmJqKwsLDVe/+ckAPAuHHjAACZmZkdHywREd0WqUSMEaFu+OfcoVj4QBgUtnJ8e+AC/u+zXxF3LAtV19VCh0hEJCjBaspTUlLg6+sLKyvDlflhYWHQ6XRISUmBs7Nzu59XVFQEAFAoFB0aJxERdRyxSISB/ZwwsJ8TLuSWYfdvOYg7loXd8dm4O6wPJgz1hJOdhdBhEhF1OcGScpVKBRcXl2bHlUolALQ5U96StWvXQiKRYMKECbcUT2t/SuhsSiUXpv4Rx8MQx6MJx8L0KJU2uHOQJ7ILKhBzKAOHknLx06krGDXIHQ+M6QdvN1uhQyQi6jKCJeU1NTWQyZrv/HZjkWZtbW27n7Vz505s3boV8+bNg5eX1y3Fw5py4XE8DHE8mnAsTJulRIRHx/XDpCGe2HfiMn4+nYdDibkI83PE5Du80c/Djh1biMgktFVTLlhSbm5uDrW6eQ3hjWS8vR1UTp48iddeew2jR4/Giy++2KExEhFR13G0M8dfxvXDtBE++CkpFwdO5uK9TUnwc7fF5GHeCO/nBDGTcyIyUYIl5UqlssUSFZVKBQDtqidPTU3Fc889h4CAAHzwwQeQSLiCn4iop7O2kOHeEb6YONQLx5LzsTchBx/HnIGboyWihnlheIgrpBIxjp8rQMyRTBRX1MLRVo4Zo/wwPMRV6PCJiG6JYEl5YGAgNm7ciOrqaoPFnqdPn9afb0tOTg6eeuopODg44D//+Q8sLS07NV4iIupacpkEYyM9MHpQH5xILcTu33Lw9a5UbD+ahf4edki6UAS1RgsAKK6oxfrdqQDAxJyIeiTBWiJGRUVBrVZjy5Yt+mN1dXWIiYlBRESEfhFoXl5eszaHKpUKTz75JEQiEb788ks4ODh0aexERNR1JGIx7gh2xVtPDMGiB8PhorBAfEqhPiG/oU6jRcwRtsUlop5JsJny8PBwREVFYdWqVVCpVPDy8kJsbCzy8vKwfPly/XVLlixBQkIC0tLS9MeeeuopXL58GU899RQSExORmJioP+fl5dXmbqBERNQziUQihPZ1RGhfRzz53k8tXlNcUQu1RguZlLuFElHPIlhSDgArVqzA6tWrERcXh/LycgQEBGDNmjWIjIxs877U1IY/Ua5bt67Zufvvv59JORGRiXO0laO4ouUuXQs/OooBPg4I83dEmJ8T7KzMujg6IiLjiXQ6Xdf2Aeym2BJReBwPQxyPJhwL+rPj5wqwfncq6v5QwmImFWNMhDtq1VqczihCaWVD0u7rZotwf0eE+znBy8Wa7RWJSDDdsiUiERHRrbqxmLO17iu6Cf1xubAKpzOLkZxRhLijWdh+NAsKGznC/BoS9CAfBeQydu0iou6BM+WNOFMuPI6HIY5HE44F3a6K6jokZxbjdGYRzmaVoLauHjKpGEHeCoT7NZS5ONqZCx0mEZk4zpQTEVGvZmtlhpFhbhgZ5gZNvRZpl8twOqMIpzOKkJxZDCAdns7W+jIXXzdbiMUscyGirsOZ8kY3mylXq+tQWVkGjaYOWm19h7ymWCyGVqu9+YW9hCmMh0QihbW1PSwsrG5+8U1wdrgJx4I6i06nQ0HJNZzOKMbpjCJcyC2HVqeDjaUMYX0dEe7vhBBfB1jIOYdFRLevrZlyJuWN2krKr1+vRmVlKayt7SCXW0AslnTIQiGpVAyNpmcnoR2pp4+HTqeDWl2HsjIVbGwUt52YMxFtwrGgrlJdo8bZiyU4nVGEMxeLUV2jgUQsQn9Pe4T7OyHc3xEuCm5WR0S3hkl5O7SVlKtUebCzc4CZWcfWG/b0JLSjmcp41NXVory8CEql+209h4loE44FCaFeq0XmlYqGMpfMYuQVVQMAXB0sMbAxQfdzt4NUwp7oRNQ+rCm/TfX1ashkcqHDoB5CJjNDfb1G6DCI6DZJxGL097RHf097zBzjj8Ky60huTNAPJF7GnoQcWMqlGNDXAeH+Tgjt6whrC5nQYRNRD8WkvJ3Y15bai98rRKbJ2d4C4wZ7YtxgT1yv1eD8pVKczmxYKJqQUgiRCPB3t2soc/FzRB8nK/48IKJ2Y1JORERkJAu5FJEBSkQGKKHV6XApv7KxzKUIWw9nYuvhTDjZmSPczwnh/RwR4KmATMoyFyJqHZNy6lQvvPAMAOCTT9Z06b1ERF1FLBKhbx9b9O1ji/vv7ovSytqGGfSMYhxNzsPBpFzIZRKE+Do09kR3hJ01SyKJyBCT8l5q5MjB7bpuy5YdcHPr08nREBGZDoWNHKMHumP0QHfUqeuRmlPa0HIxswhJ6SoAgK+bTcMsur8TvFysWeZCROy+ckNb3VcKCrLh6urd4a8pZLeRvXt3GXy9efP/cPVqPhYsWGxw/O67x8DCwuKWX0etVgMAZLKbL37683gYc2930xHfM+w40oRjQaZAp9MhV1WtL3O5eKUCOgD21mYI82vo5hLs7QC5mUToUImok7D7CjUzceJkg68PHz6I8vKyZsf/rKamBubm7W8NeTsJdU9MxomIWiMSieDpbA1PZ2tMvdMHFdV1OHOxYdOihJSr+Pl0HqQSMYK8FfqdRR3tOrYVLxF1X0zKqVUvvPAMqqqq8Morf8PHH3+AtLRUzJo1G3PnzsPRo4exY0cs0tPTUFFRDqXSGZMnT8Njjz0BiURi8AygqS48KekkFi58FsuWrUBW1kVs374NFRXlCA0Nx6uvvgY3N49buvf//u9v8PDwNIh/27bN+O67TSguLoKfnx9eeGER1q793OCZRERCsbUyw4hQN4wIdYOmXov0y2X6nUW/2VeMb5AOD6V1Q4Lu74S+brYQi1nmQmSqmJQL5Pi5AsT8fBHF5TVwtJVjxig/DA9xFTqsZsrKSvHKK4swYUIUoqKmwMWlIcZdu36AhYUlHnpoFiwtLZCYeBLr1n2B6upqzJ//4k2fu379lxCLJXjkkdmorKzA//63EX//++tYs+a/t3TvP/7xOtauXa+/JjZ2Kz74YAUGDozAQw/9Bfn5+Vi69GXY2NhAqXS+5fEgIuoMUokYwT4OCPZxwMNj/VFQcg2nM4qRnFmE3b/l4Mfj2bC2kCHMryFBD/FxgKV506/w4+cKEHMkE8UVtd36dwoRtY5JuQCOnyvA+t2pqGusny6uqMX63akA0O1+iBYVqfDqq29g6tT7DI6/9dY7kMub/qw6fXo0Vq58F7GxW/D008/BzMyszedqNBp89dV6SKUN34K2tnb48MNVuHgxA337+t/WvWq1GuvWfY6QkFCsXv2Z/jp//35YtuwtJuVE1K2JRCK4OVrBzdEKUcO8UF2jxtmLJTidWYTTGUX49WwBJGIR+nvaI9zPEVqdDtuPZvWI3ylE1Dom5bfhlzP5OJacb/R9mXnl0NQbLiqt02jx9a4U/Px7ntHPGxnW8OfPzmBubo6oqCnNjv8xIb92rRp1dWqEhw9CXFwMsrMvoV+//m0+d8qUe/XJMgCEhw8EAOTlXblpUn6ze1NTz6O8vBzPP3+/wXXjx0fho4/eb/PZRETdjZW5DMOCXTAs2AX1Wi0yr1ToWy5+91NGi/fUabSIOZLJpJyoB2FSLoA/J+Q3Oy4kpdLZILG94eLFTKxd+zmSkk6gurra4Fx1ddVNn3ujDOYGGxtbAEBl5c07bNzs3oKChg9Kf64xl0qlcHPrnA8vRERdQSIWo7+nPfp72mPmaH+oyq5jyRfHW7y2uKIWWfkV8HaxYS06UQ/ApPw23FigY6z/++wXFFfUNjvuaCvHklkRHRFah/njjPgNlZWVWLDgGVhaWmPu3Gfh7u4BMzMzpKen4vPPP4ZWe/M2j2Jxyy2/2tOh83buJSIyJUp7Czjaylv8nQIAb68/CUu5FIHeCgR5KxDso4CrgyX7ohN1Q0zKBTBjlJ9BTTkAmEnFmDHKT8Co2u/UqUSUl5dj2bKVGDiw6UNEfr7xpTedwdW14YNSbu5lhIcP0h/XaDTIz8+Hn1/b5TFERD1Ja79TZt7jDytzKVIuleL8pVL9xkX21mYI8nZAsE9Dou5gy7aLRN0Bk3IB3Kjx6wndV1oiFosBGM5Mq9VqxMZuESokA4GBwbCzs8OOHbGYOHGyvvxm//49qKysEDg6IqKOpf+d0kr3lTuCXaHT6aAqu47z2aVIuVSKMxeLcfxcAQDA1cESQT4KBHsrEOitgJU594ggEgKTcoEMD3HFXeF9BNvR83aEhobBxsYWy5a9hejohyASibB37y50l+oRmUyGJ598Bh98sBIvvfQ8xowZi/z8fOzevRPu7h78sy0RmZzhIa5tTuyIRCI4KyzhrLDE6IHu0Op0yC2swvlLpUjJLsWvZwpwKOkKRAC8XW0ak3QH+HvYQS7jDqNEXYFJORnNzs4eK1Z8gE8+WY21az+HjY0tJkyYhMGDh2Lx4heEDg8A8MADD0Gn0+G77zbh008/hJ9fP7z33vtYvXoVzMzkQodHRCQosUgELxcbeLnYIGqYFzT1WlzMq0BKdilSLpVgX8Jl7P4tB1KJCP7udgjyViDIxwG+bjaQNP61lIg6lkjH1XEAgOLiKmi1LQ9FQUE2XF29O/w1pVJxj5wp7yydPR5arRZTp47HqFFjsGTJ6532OkDHfM8olTZQqW7ejaY34FgQda2aOg3SL5cjJbsEKZdKkVPY0FXLQi5BgKeiMUlXwN3Jin99JDKCWCyCo6N1i+c4U04mqba2FnK54Yz4nj0/oqKiHIMGRQoUFRFRz2BuJkWYnyPC/BwBAJXX6pCaU4bzlxqS9N8zigAAtlZmCPZuStKd7CyEDJuoR2NSTiYpOfl3fP75xxg9+h7Y2tohPT0VP/64A337+mHMmHFCh0dE1KPYWJphSKAzhgQ27IhcVH4dKY316OezS/Hb+asAAGd7i4Z6dB8HBHrZw8ay7d2diagJk3IySX36uMPJSYmtW79HRUU5bG3tEBU1Bc8++wJkMnYWICK6HU52Frgr3AJ3hfeBTqfDlaJqfZIef/4qjjTuTu3lbI0gHwWCvB3Q39MO5mZMO4haw5ryRqwpF54pjQdryjsWx4Ko56jXanEpv7Kx/WIJMq6UQ1Ovg0Qsgl8fWwT5OCDIW4G+fWwhlXDRKPUurCknIiKiLiERi+Hnbgc/dztMu9MHtep6ZOSW43zjotEdx7IQdywLcpkE/T3t9TuNejhbQ8xFo9SLMSknIiKiTiOXSRDi64AQXwcAQNV1NdJySg02MgIAawuZfsFosLcCSnsLdnahXoVJOREREXUZawsZIgOcERnQsGi0pKKmYcHopVKkZJfgRGohAMDR1hzBPgp9TbqdFReNkmljUk5ERESCcbA1x4hQN4wIdYNOp0NByTX9TqOJaSocTc4HALgrrRpLXRwQ4GkPCzlTGDIt/I4mIiKibkEkEsHN0QpujlYYG+kBrVaH7KuVDf3Rs0tx5Pc8HDiZC7FIBN8+NgjydkCwtwJ+7naQSZsWjR4/V4CYI5korqiFo60cM0b5YXiIq4DvjOjmBE3K6+rq8OGHHyIuLg4VFRUIDAzEokWLMHz48DbvS05ORkxMDJKTk5Geng61Wo20tLQuipqIiIi6glgsgq+bLXzdbDFluA/UmnpkXKlASnYJzl8qxY/HL+GHXy/BTCpGP097BHsroKnX4sfj2ahr7OZVXFGL9btTAYCJOXVrgiblr776Kvbt24fZs2fD29sbsbGxePrpp7Fx40YMGjSo1fuOHDmCLVu2ICAgAJ6enrh48WIXRk1ERERCkEklDYtBvRWYcTdwrUaDtMul+h7pWw5ntnhfnUaLmCOZTMqpWxOsT3lycjJmzpyJpUuX4vHHHwfQsDX61KlT4ezsjE2bNrV6b1FREaytrWFubo5ly5Zhw4YNtz1Tzj7lwjOl8WCf8o7FsSCi9iirqsXiT35p9fzz0wcg0FsBawtuIkfCaKtPuWBd+/fs2QOZTIaZM2fqj8nlckRHRyMxMRGFhYWt3uvk5ARzc/OuCJPaadeunRg5cjDy8/P0x6Kjp2HZsrfafW9eXt5Nr22vpKSTGDlyMJKSTnbYM4mIqHuzt5bD0Vbe6vnPtp/Fix8dxdvrTyLm50yk5ZRCU28ak0HU8wlWvpKSkgJfX19YWVkZHA8LC4NOp0NKSgqcnZ0Fis70vfLKIiQlncDOnfthYWHR4jWLF7+Ac+fOYMeOfZDLW/8hJ6QDB/aipKQYDz74iNChEBFRNzBjlB/W707V15QDgJlUjMcmBsBZYYFzWQ316LuO5+CHX7Mhl0kQ4GWPEB8HBPs6oI+jJfujkyAES8pVKhVcXFyaHVcqlQDQ5kw53b7x4yfi11+P4tixIxg/PqrZ+dLSEiQmnsCECZNuOSH/9tttEIs7948xBw/uw4UL6c2S8oEDI3Dw4C+QyfgnSiKi3uRG3Xhr3Vf6edhj+l0N9eipOaU4d6kE57NKkJzZsImRvbWZPkEP9mF/dOo6giXlNTU1LSZMNxLA2traLo2ntfoeACgsFEMq7ZzksrOeezNjxozBypWWOHhwHyZNmtzs/JEjB1FfX4+oqMntilEsbphVkEiaxkoqbV+J0Y17G+4xbjxuzGY0v08MMzPh1jGLxWIolTa3/ZyOeIap4FgQUXvdO9oG947ud9PrvD0VmDiiLwCgsOQaTqWrcCq9EMkXVPjlbAEAwLePLQb2d8bA/kqE9HWEXCbp1Nip9xIsazE3N4darW52/EYy3tXlEm0t9NRqtZ2yAFHIhY1SqRwjR47CoUMHUFJSBltbW4Pze/fugaOjI9zdPfHee+8iMTEBV69ehbm5OSIiBmP+/Bfh5tZHf/2Nsauvbxqr6OhpGDQoEq+99pb+uosXM7F69UqcPXsGdnZ2uO++GXByUurP37j36NHD2LEjFunpaaioKIdS6YzJk6fhsceegETS8APxhReewe+/JwEA7rgjAgDg6uqGrVt3IinpJBYufBYfffQFIiIG659/8OA+fPPNf5GdfQmWllYYMeIuPPfcQtjb2+uveeGFZ1BVVYU33/wn3n9/BVJSzsHGxhYzZz6MWbPmtGt8tVrtbS9M5OLGJhwLIupsIgARfg6I8HOAdmKAvj/6uawS7DyaidjDGZBKxOjvadcwk+7jAE8Xa4hZ6kJGaGuhp2BJuVKpbLFERaVSAYDJ15MnFCRh58U9KKkpg0Juj3v9ojDUNaJLYxg/Pgr79u3G4cMHce+99+uPFxTk4+zZZERHP4yUlHM4ezYZ48ZNhFLpjPz8PGzfvg0LFszDN99sMWrBbXFxERYufBZarRaPPjoH5uYW2LEjtsUPYLt2/QALC0s89NAsWFpaIDHxJNat+wLV1dWYP/9FAMCcOU/i+vXruHo1HwsWLAYAWFhYtvr6u3btxLvv/gMhIaF47rmFKCy8im3bvkdKyjmsXbvBII6KinL89a8LMWbMWIwdOwGHDh3A559/jL59/TF8+Ih2v2ciIup5/twfvbauHmmXyxqS9Eslja0XM2FjKUOQtwIhvg4I8XGAgy2bUNCtEywpDwwMxMaNG1FdXW2w2PP06dP686YqoSAJ36Zug1rb8JeC0toyfJu6DQC6NDEfMmQY7O0VOHBgr0FSfuDAXuh0OowfPxF+fv4YM2acwX0jRtyNZ599AocPH0RU1JR2v96mTetRXl6Gdes2IiCg4f/fSZOm4i9/ub/ZtW+99Q7k8qYfbtOnR2PlyncRG7sFTz/9HMzMzDBkyB2IidmC8vIyTJzYvATnjzQaDT7//GP4+/fHxx//B2ZmDTWCAQGBeOut17BzZyyiox/WX19YeBV///s7+nr7qVPvQ3T0VPz4YxyTciKiXkZuJkGYnyPC/BwBNLRevDGLfv5SKRJSGiYZ3RwtEezTkKAHeNnDQs6N06n9BPtuiYqKwldffYUtW7bo+5TX1dUhJiYGERER+kWgeXl5uH79Ovz8/IQKtVXx+Yk4nn/C6PuyynOg0WkMjqm1amxK2Ypf8xKMft5wtyEY5hZp9H1SqRT33DMO27dvQ1FREZycnAAABw7sg4eHJ4KDBxhcr9FoUF1dBQ8PT1hb2yA9PdWopPz48V8QGhquT8gBQKFQYPz4SYiN3WJw7R8T8mvXqlFXp0Z4+CDExcUgO/sS+vXrb9R7TU09j9LSEn1Cf8M994zHp59+iF9//cUgKbe2tsa4cRP1X8tkMgQFhSAv74pRr0tERKbH3lqOOwe44c4BbtDpdLiiqsa5xln0o6fzcDAxFxKxCH59bBHcOIvu42YDSSc3P6CeTbCkPDw8HFFRUVi1ahVUKhW8vLwQGxuLvLw8LF++XH/dkiVLkJCQYLA50JUrVxAXFwcAOHPmDADgs88+A9Aww37PPfd04Tsx3p8T8psd70zjx0chJmYLfvppHx588BFcupSFjIx0PPHE0wCA2toabNz4X+zatRMqVSH+uNdUVVWVUa919WoBQkPDmx338mq+yc7Fi5lYu/ZzJCWdQHV1tcG56mrjXhdoKMlp6bXEYjE8PDxx9Wq+wXFnZ5dmLbFsbGyRmZlh9GsTEZHpEolE8HC2hoezNSYO9YJaU4+M3HKcu9TQ2SXuaBa2H82ChVyKYG9FY5KugLOi9XJL6p0E/bvKihUrsHr1asTFxaG8vBwBAQFYs2YNIiPbnvXNzc3Fhx9+aHDsxtf3339/lyXlw9wib2mG+vVf3kVpbVmz4wq5PV6KeLYjQmu30NBwuLm5Y//+PXjwwUewf/8eANCXbXzwwUrs2rUTM2f+BQMGhMLa2hqACG+99Td01mawlZWVWLDgGVhaWmPu3Gfh7u4BMzMzpKen4vPPP4ZW2/mLY8XillfXC7QBLhER9RAyqQRBPg4I8nFANPxQea0OKdmljaUuJUhMb1g752Rnrq9F5y6jBAiclMvlcixZsgRLlixp9ZqNGzc2OzZs2DCDmfOe5l6/KIOacgCQiWW41695v/CuMG7cBGzc+DVycy/j4MF9CAgI0s8o36gbX7Bgkf762tpao2fJAcDFxRW5uZebHc/JyTb4+tSpRJSXl2PZspUYOLCpxv6Pu4U2ad+qd1dXN/1r/fGZOp0OubmX4evb/cqjiIio57OxNMPQIBcMDXKBTqfD1dLrOJfVUI8ef/4qjvyeB5EI8HG1RYivAiE+DvBzt4NUwlKX3oYrEARwYzGn0N1XbpgwYRI2bvwan3zyAXJzLxsk4C3NGG/b9j3q6+uNfp3hw0dgy5bvkJaWqq8rLy0txf79uw2uu7Hh0B9npdVqdbO6cwCwsLBo1weEwMBgKBQO2L59KyZNmqrvkX/o0EGoVIWYNWu20e+HiIjIGCKRCK4OlnB1sMTYSA9o6rXIyq9oSNIvlXCX0V6OSblAhrpG4E6PwYL1Kf8jX9++8Pfvj2PHfoZYLMbYsU0LHO+8cyT27t0FKytr+Pj44ty5Mzh5MgF2dnZGv84jj8zB3r27sHjxfERHPwy53Bw7dsTCxcUNVVUX9NeFhobBxsYWy5a9hejohyASibB37y60VDkSEBCIfft24+OP30dgYDAsLCwxcuTdza6TSqV47rkFePfdf2DBgnkYN24CCguvYuvW79G3rx+mTWveAYaIiKgzSSVi9POwb9xltG+ru4wqbOQIbmy9GOzjAFvuMmqSmJQTAGDChChkZKRj0KBIfRcWAHjxxZchFouxf/9u1NbWITQ0HKtXf4rFixcY/RpOTk746KP/4IMPVmDjxv8abB703ntv66+zs7PHihUf4JNPVmPt2s9hY2OLCRMmYfDgoVi8+AWDZ9533wNIT0/Frl0/4Pvvv4Wrq1uLSTkATJ48DWZmZti0aT0+/fRDWFlZYfz4KDz77IIu36yKiIjozyzNpYjor0RE/4ZN9YrKrjd2dSnF7xlF+l1GPZ2tG2fRFejvYQ8z7jLabsfPFSDmSCaKK2rhaCvHjFF+GB7iKnRYAACRjivXALS9o2dBQTZcXZt3CLldQu7o2R2Z0nh0xPcMd7FswrEgot5Oq9UZ7DJ6Ibcc9VrdTXcZ7c5JaFc7fq4A63enou4PuYaZVIw5kwK7bEy65Y6eRERERA3hj78AAAxMSURBVNQ+xuwyGuzjgGAfBWrq6rHtcKY+CS2uqMX63akA0OlJqFang0ajhaZeC029Dpp6LdQ3/l1/vOFrdb224ZhWC41G1+xc/Y17NbrGa5o/t/6Pz6n/4zOanlNb13w9XJ1Gi5gjmd3igwqTciIiIqIe5s+7jJZWNuwyer6x3CX+/NUW76vTaPG/A+mtJMx/TppbSXqbJc9aqOt1BsmztoMLMaQSEaQSceM/Df8uk4ohEYshkzZ+LRHDwkxqcK1MKoKk8dy+E807wAENH1a6AyblRERERD2cwkaOEaFuGBHatMvom1+1vEt41XUNvm6cMf8jkQiQ/THxlYoNEmGZRAyJRAxzmQRS88bjUrFhEiwRQ9J4rVQqhlT8x+eI/nCNGLIWXqMpmRZDIhbp/7cjus8kphW2mIA72naPdWVMyomIiIhMyI1dRh1t5S0mofbWZnjtscEGCbVMIoZYbNptF2eM8muxpnzGqO6xVwk70xMRERGZoBmj/GAmNUz1zKRizBzjD0c7c9hZmcHKXAa5TGLyCTnQUEc/Z1Kgfmbc0VbepYs8b4Yz5UREREQm6Eayye4rTYaHuHbb98+kvJ10Oh1306J2YZdRIiLqLrpzEkqGWL7SDhKJDGp191iZS92fWl0HiYSfd4mIiKj9mJS3g7W1HcrKilBdXYn6eg1nQqlFOp0OdXW1KCtTwdraXuhwiIiIqAfhdF47WFhYQSqVoaqqDNXV5dBqmzefvxVisRharWnsYNkRTGE8JBIpbGwUsLCwEjoUIiIi6kGYlLeTTGYGhcK5Q5/JrcMNcTyIiIiot2L5ChERERGRwJiUExEREREJjEk5EREREZHAmJQTEREREQmMSTkRERERkcDYfaWRWCzMbp1CvW53xfEwxPFowrEgIqKerq3fZSIdd8IhIiIiIhIUy1eIiIiIiATGpJyIiIiISGBMyomIiIiIBMaknIiIiIhIYEzKiYiIiIgExqSciIiIiEhgTMqJiIiIiATGpJyIiIiISGBMyomIiIiIBMaknIiIiIhIYFKhA+htCgsLsWHDBpw+fRpnz57FtWvXsGHDBgwbNkzo0LpccnIyYmNjER8fj7y8PNjb22PQoEF46aWX4O3tLXR4Xe7MmTP44osvcP78eRQXF8PGxgaBgYGYP38+IiIihA5PcGvXrsWqVasQGBiIuLg4ocMhIiLqUEzKu1hWVhbWrl0Lb29vBAQE4NSpU0KHJJh169YhKSkJUVFRCAgIgEqlwqZNmzB9+nRs3boVfn5+QofYpS5fvoz6+nrMnDkTSqUSlZWV2LlzJx599FGsXbsWI0aMEDpEwahUKnz++eewtLQUOhQiIqJOIdLpdDqhg+hNqqqqoFaroVAocODAAcyfP7/XzpQnJSVhwIABMDMz0x+7dOkSpk2bhilTpuC9994TMLru4fr16xg3bhwGDBiA//znP0KHI5hXX30VeXl50Ol0qKio4Ew5ERGZHNaUdzFra2soFAqhw+gWIiIiDBJyAPDx8UG/fv2QmZkpUFTdi4WFBRwcHFBRUSF0KIJJTk7Gjh07sHTpUqFDISIi6jRMyqlb0el0KCoq6tUfXKqqqlBSUoKLFy/i/fffR3p6OoYPHy50WILQ6XR4++23MX36dAQFBQkdDhERUadhTTl1Kzt27MDVq1exaNEioUMRzN/+9jfs3bsXACCTyfDwww/j2WefFTgqYWzfvh0ZGRn49NNPhQ6FiIioUzEpp24jMzMT//znPxEZGYn77rtP6HAEM3/+fDz00EMoKChAXFwc6urqoFarm5X6mLqqqir8+9//xjPPPANnZ2ehwyEiIupULF+hbkGlUv1/e/cSElX/x3H8o+ZjUFpoE4TaxQLFC46LLiqKeYEIw6BAUqdQk8oMLGxTtAiKgiwqy7AMsk0uTBiYRWkpWA0UREloEpaVQxdLsywvmc5/8fAM+R///6dFekzfr935nu843zPO4sOZ3zlHO3bs0Lx583TmzBl5es7cr2ZoaKji4+O1adMmXb58WS0tLTNyPfWFCxfk7e2t3Nxco0cBAGDCzdzkgymjr69PBQUF6uvrU2VlpUwmk9EjTRne3t5KSUlRXV2dBgcHjR5n0nR1damqqkpZWVn6+PGjHA6HHA6HhoaGNDw8LIfDoc+fPxs9JgAAvw3LV2CooaEh7dy5Uy9fvtSVK1cUEhJi9EhTzuDgoJxOp759+6bZs2cbPc6k6O7u1vDwsEpLS1VaWuq2PyUlRQUFBSopKTFgOgAAfj9COQwzMjKi4uJiPX78WOXl5TKbzUaPZKienh75+/uPqX39+lU3b97UokWLFBAQYNBkky8oKGjciztPnz6t/v5+HThwQEuXLp38wQAAmCCEcgOUl5dLkute3FarVQ8fPpSfn59ycnKMHG1SHT9+XA0NDVq7dq16e3vHPBBmzpw5Sk1NNXC6yVdcXCwfHx/FxMTIZDLp7du3qq2t1bt373Tq1Cmjx5tUvr6+4/7/q6qq5OXlNeO+GwCA6Y8nehogNDR03HpgYKAaGhomeRrjWCwWPXjwYNx9M+2zkKSamhpZrVa1t7fry5cv8vX1ldlsVl5enlatWmX0eFOCxWLhiZ4AgGmJUA4AAAAYjLuvAAAAAAYjlAMAAAAGI5QDAAAABiOUAwAAAAYjlAMAAAAGI5QDAAAABiOUAwAAAAYjlAMADGOxWJScnGz0GABguFlGDwAA+L3u37+vrVu3/s/9Xl5eam1tncSJAAD/hlAOANNUenq6EhMT3eqenvxICgBTDaEcAKap8PBwZWRkGD0GAOAXcLoEAGYoh8Oh0NBQlZWVyWazacOGDYqKilJSUpLKysr048cPt9e0tbVp9+7dWr16taKiorR+/XpdunRJIyMjbr0fPnzQkSNHlJKSosjISMXGxio3N1f37t1z633//r327dunlStXKjo6Wvn5+ero6JiQ4waAqYgz5QAwTQ0MDKinp8et/tdff2nu3Lmu7YaGBnV2dio7O1sLFixQQ0ODzp07pzdv3ujYsWOuvidPnshisWjWrFmu3sbGRpWWlqqtrU0nT5509TocDm3ZskXd3d3KyMhQZGSkBgYG1NzcLLvdrvj4eFdvf3+/cnJyFB0drb1798rhcOjq1asqLCyUzWaTl5fXBH1CADB1EMoBYJoqKytTWVmZWz0pKUkVFRWu7ba2NtXU1CgiIkKSlJOTo6KiItXW1iozM1Nms1mSdPToUX3//l3V1dUKCwtz9RYXF8tms2nz5s2KjY2VJB0+fFhdXV2qrKxUQkLCmPcfHR0ds/3p0yfl5+eroKDAVfP399eJEydkt9vdXg8A0xGhHACmqczMTK1bt86t7u/vP2Y7Li7OFcglycPDQ9u3b9etW7dUX18vs9ms7u5uPXr0SGlpaa5A/k/vrl27dOPGDdXX1ys2Nla9vb26c+eOEhISxg3U/32hqaenp9vdYtasWSNJevXqFaEcwIxAKAeAaWrJkiWKi4v7177ly5e71VasWCFJ6uzslPT3cpSf6z8LCQmRp6enq/f169dyOp0KDw//pTkXLlwoHx+fMbX58+dLknp7e3/pbwDAn44LPQEAhvp/a8adTuckTgIAxiGUA8AM9/z5c7dae3u7JCk4OFiSFBQUNKb+sxcvXmh0dNTVu3jxYnl4eOjp06cTNTIATDuEcgCY4ex2u1paWlzbTqdTlZWVkqTU1FRJUkBAgGJiYtTY2Khnz56N6b148aIkKS0tTdLfS08SExPV1NQku93u9n6c/QYAd6wpB4BpqrW1VVarddx9/4RtSQoLC9O2bduUnZ0tk8mk27dvy263KyMjQzExMa6+gwcPymKxKDs7W1lZWTKZTGpsbNTdu3eVnp7uuvOKJB06dEitra0qKCjQxo0bFRERoaGhITU3NyswMFD79++fuAMHgD8QoRwApimbzSabzTbuvrq6Otda7uTkZC1btkwVFRXq6OhQQECACgsLVVhYOOY1UVFRqq6u1tmzZ3Xt2jX19/crODhYJSUlysvLG9MbHBys69ev6/z582pqapLVapWfn5/CwsKUmZk5MQcMAH8wDye/IwLAjORwOJSSkqKioiLt2bPH6HEAYEZjTTkAAABgMEI5AAAAYDBCOQAAAGAw1pQDAAAABuNMOQAAAGAwQjkAAABgMEI5AAAAYDBCOQAAAGAwQjkAAABgMEI5AAAAYLD/AEFwZdmzTXWYAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935236030,"user_tz":-120,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"22e8a253-225b-4ac8-b17f-034fb870b280"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","test_df = pd.read_csv(\"stockholm/wikipedia_tech/nouns/wiki_tech_nouns_replaced_500.csv\")\n","test_df = test_df[test_df[\"prediction\"] == 0]\n","test_df = test_df.rename(columns={'prediction': 'label'})\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Number of test sentences: 499\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg","executionInfo":{"status":"ok","timestamp":1629935236033,"user_tz":-120,"elapsed":23,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qmj7fm818zxM","executionInfo":{"status":"ok","timestamp":1629935236383,"user_tz":-120,"elapsed":372,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K","executionInfo":{"status":"ok","timestamp":1629935236392,"user_tz":-120,"elapsed":45,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh","executionInfo":{"status":"ok","timestamp":1629935236395,"user_tz":-120,"elapsed":47,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc","executionInfo":{"status":"ok","timestamp":1629935236397,"user_tz":-120,"elapsed":48,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = final_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W","executionInfo":{"status":"ok","timestamp":1629935236400,"user_tz":-120,"elapsed":50,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"status":"ok","timestamp":1629935236406,"user_tz":-120,"elapsed":56,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"08311adb-375e-4bb8-b2ed-0623db08d057"},"source":["my_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['Knowledge (\"science of craft\", from Greek τέ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Methods (e</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>g</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>systems) applying technology by taking an inp...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The prehistoric discovery of shaped stone tool...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  correct_label  label\n","0  ['Knowledge (\"science of craft\", from Greek τέ...              0      0\n","2                                         Methods (e              0      0\n","3                                                  g              0      0\n","4   systems) applying technology by taking an inp...              0      0\n","6  The prehistoric discovery of shaped stone tool...              0      0"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935236408,"user_tz":-120,"elapsed":55,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"5873b512-5544-4b25-d1f8-d10341d9a1ad"},"source":["my_submission.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(252, 3)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935236411,"user_tz":-120,"elapsed":47,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"afa961ea-3b72-4922-9dca-546eaf9bd5b4"},"source":["test_df.label.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    252\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n","executionInfo":{"status":"ok","timestamp":1629935236764,"user_tz":-120,"elapsed":396,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==1)]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629935236765,"user_tz":-120,"elapsed":38,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"53c9ac65-4f92-4d61-cb74-2b94c3215572"},"source":["final.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7, 3)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7","executionInfo":{"status":"ok","timestamp":1629935236765,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission.to_csv('stockholm/wikipedia_tech/wiki_xlm_sub.csv', index=False)"],"execution_count":38,"outputs":[]}]}