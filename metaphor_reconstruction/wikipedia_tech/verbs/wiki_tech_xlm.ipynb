{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"wiki_tech_xlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398179864,"user_tz":-120,"elapsed":214,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"177a82f4-0208-4997-d454-7d0e3d076735"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398182473,"user_tz":-120,"elapsed":2255,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c9ecda2a-c7a9-49ca-88b1-b64ab8dcd2d4"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398182809,"user_tz":-120,"elapsed":342,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"d0953316-108c-4bb1-cd83-eff568423c4f"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L","executionInfo":{"status":"ok","timestamp":1630398182811,"user_tz":-120,"elapsed":8,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398185254,"user_tz":-120,"elapsed":2450,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"cc75dbcf-e67c-4525-b79d-2f6a1e0a5896"},"source":["!pip install transformers==3"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1630398185256,"user_tz":-120,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"fed7ebee-e752-493a-c166-85f88d163f44"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"]}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB","executionInfo":{"status":"ok","timestamp":1630398185257,"user_tz":-120,"elapsed":22,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"stockholm/wikipedia_tech/verbs/wiki_tech_labels_500.csv\")\n","data = data.rename(columns={'prediction': 'label'})\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1630398185259,"user_tz":-120,"elapsed":24,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9656780d-1835-440f-92dd-40b9a0cb3336"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"stockholm/wikipedia_tech/verbs/wiki_tech_labels_500.csv\")\n","df = df.rename(columns={'prediction': 'label'})\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training sentences: 499\n","\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['Technology (\"science of craft\", from Greek τ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Technology can be the knowledge of techniques...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Systems (e</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>g</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>machines) applying technology by taking an in...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  ['Technology (\"science of craft\", from Greek τ...      0\n","1   Technology can be the knowledge of techniques...      1\n","2                                         Systems (e      0\n","3                                                  g      0\n","4   machines) applying technology by taking an in...      0"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1","executionInfo":{"status":"ok","timestamp":1630398185262,"user_tz":-120,"elapsed":22,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398185263,"user_tz":-120,"elapsed":22,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9cf52e40-c96e-4746-bbf7-da7d8dc2b29b"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values.astype(str)\n","labels = df.label.values\n","labels"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n","       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n","       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n","       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n","       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1630398187613,"user_tz":-120,"elapsed":2369,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b2e576b3-b4ca-4a2d-a464-9c36c5645a0c"},"source":["!pip install sentencepiece"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398188617,"user_tz":-120,"elapsed":1014,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"964e9c4f-1932-4869-bc55-5258434c765c"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading XLMRobertaTokenizer ...\n"]}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398189004,"user_tz":-120,"elapsed":23,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"179ce94e-d718-4a25-85ee-a6146c57ab44"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  ['Technology (\"science of craft\", from Greek τέχνη, techne, \"art, skill, cunning of hand\"; and -λογία, -logia) is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation\n","Tokenized:  ['▁[', \"'\", 'tech', 'n', 'ology', '▁(\"', 'science', '▁of', '▁craft', '\",', '▁from', '▁gre', 'ek', '▁', 'τέ', 'χ', 'νη', ',', '▁tech', 'ne', ',', '▁\"', 'art', ',', '▁skill', ',', '▁cun', 'ning', '▁of', '▁hand', '\";', '▁and', '▁-', 'λογ', 'ία', ',', '▁-', 'logia', ')', '▁is', '▁the', '▁sum', '▁of', '▁techniques', ',', '▁skills', ',', '▁methods', ',', '▁and', '▁process', 'es', '▁used', '▁in', '▁the', '▁production', '▁of', '▁good', 's', '▁or', '▁services', '▁or', '▁in', '▁the', '▁accomplish', 'ment', '▁of', '▁objective', 's', ',', '▁such', '▁as', '▁scientific', '▁investigation']\n","Token IDs:  [378, 25, 20489, 19, 25443, 24073, 175201, 111, 131346, 830, 1295, 3514, 343, 6, 16012, 2088, 9417, 4, 51216, 86, 4, 44, 3960, 4, 112419, 4, 19466, 592, 111, 3535, 56128, 136, 20, 25892, 3420, 4, 20, 81331, 16, 83, 70, 10554, 111, 53088, 4, 59376, 4, 150624, 4, 136, 9433, 90, 11814, 23, 70, 36049, 111, 4127, 7, 707, 11374, 707, 23, 70, 163846, 674, 111, 151814, 7, 4, 6044, 237, 57456, 145456]\n"]}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1630398189005,"user_tz":-120,"elapsed":20,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c24ee30a-8d80-4b6d-edc1-1b4c6a5e5402"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  ['Technology (\"science of craft\", from Greek τέχνη, techne, \"art, skill, cunning of hand\"; and -λογία, -logia) is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation\n","Token IDs: tensor([     0,    378,     25,  20489,     19,  25443,  24073, 175201,    111,\n","        131346,    830,   1295,   3514,    343,      6,  16012,   2088,   9417,\n","             4,  51216,     86,      4,     44,   3960,      4, 112419,      4,\n","         19466,    592,    111,   3535,  56128,    136,     20,  25892,   3420,\n","             4,     20,  81331,     16,     83,     70,  10554,    111,  53088,\n","             4,  59376,      4, 150624,      4,    136,   9433,     90,  11814,\n","            23,     70,  36049,    111,   4127,      7,    707,  11374,    707,\n","            23,     70, 163846,    674,    111, 151814,      7,      4,   6044,\n","           237,  57456, 145456,      2,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n","        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n","        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n","        1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n"]}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1630398189006,"user_tz":-120,"elapsed":16,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"b29c3310-9a5d-48ab-c3e0-08bf6516728f"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["  449 training samples\n","   50 validation samples\n"]}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk","executionInfo":{"status":"ok","timestamp":1630398189007,"user_tz":-120,"elapsed":9,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1630398202351,"user_tz":-120,"elapsed":13352,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"f2f072f6-4262-44ca-de6e-eaee6de3efb1"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1630398202353,"user_tz":-120,"elapsed":38,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"0715e073-1d5e-4ef1-c6e4-7aa1e51cb24f"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup","executionInfo":{"status":"ok","timestamp":1630398202354,"user_tz":-120,"elapsed":36,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg","executionInfo":{"status":"ok","timestamp":1630398202356,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv","executionInfo":{"status":"ok","timestamp":1630398202357,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR","executionInfo":{"status":"ok","timestamp":1630398202358,"user_tz":-120,"elapsed":37,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1630398263151,"user_tz":-120,"elapsed":60829,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"201fcc63-54b5-4a5a-9e92-77bb5b96672c"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.65\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.58\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.51\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.83\n","  Validation Loss: 0.46\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.34\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.38\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.83\n","  Validation Loss: 0.42\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.15\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.84\n","  Validation Loss: 0.44\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.10\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.57\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.87\n","  Validation took: 0:00:00\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.09\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.84\n","  Validation Loss: 0.60\n","  Validation took: 0:00:00\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.06\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.83\n","  Validation Loss: 0.76\n","  Validation took: 0:00:00\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.79\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Total training took 0:01:01 (h:mm:ss)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1630398263155,"user_tz":-120,"elapsed":42,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2caa0cb3-56ea-462f-b678-a20173e74d88"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.65</td>\n","      <td>0.58</td>\n","      <td>0.76</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.51</td>\n","      <td>0.46</td>\n","      <td>0.83</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.34</td>\n","      <td>0.38</td>\n","      <td>0.81</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.22</td>\n","      <td>0.42</td>\n","      <td>0.83</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.15</td>\n","      <td>0.44</td>\n","      <td>0.84</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.10</td>\n","      <td>0.57</td>\n","      <td>0.81</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.07</td>\n","      <td>0.87</td>\n","      <td>0.81</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.09</td>\n","      <td>0.60</td>\n","      <td>0.84</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.06</td>\n","      <td>0.76</td>\n","      <td>0.83</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.05</td>\n","      <td>0.79</td>\n","      <td>0.81</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.65         0.58           0.76       0:00:06         0:00:00\n","2               0.51         0.46           0.83       0:00:06         0:00:00\n","3               0.34         0.38           0.81       0:00:06         0:00:00\n","4               0.22         0.42           0.83       0:00:06         0:00:00\n","5               0.15         0.44           0.84       0:00:06         0:00:00\n","6               0.10         0.57           0.81       0:00:06         0:00:00\n","7               0.07         0.87           0.81       0:00:06         0:00:00\n","8               0.09         0.60           0.84       0:00:06         0:00:00\n","9               0.06         0.76           0.83       0:00:06         0:00:00\n","10              0.05         0.79           0.81       0:00:06         0:00:00"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1630398263712,"user_tz":-120,"elapsed":595,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"4c9dc732-14b1-4490-8586-2019be27dca4"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398263714,"user_tz":-120,"elapsed":17,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a9ce89c5-aade-4754-c100-4e2a32a3f146"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","test_df = pd.read_csv(\"stockholm/wikipedia_tech/verbs/wiki_tech_verbs_replaced_500.csv\")\n","test_df = test_df[test_df[\"prediction\"] == 0]\n","test_df = test_df.rename(columns={'prediction': 'label'})\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of test sentences: 499\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg","executionInfo":{"status":"ok","timestamp":1630398263717,"user_tz":-120,"elapsed":14,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qmj7fm818zxM","executionInfo":{"status":"ok","timestamp":1630398264107,"user_tz":-120,"elapsed":403,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K","executionInfo":{"status":"ok","timestamp":1630398264112,"user_tz":-120,"elapsed":48,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh","executionInfo":{"status":"ok","timestamp":1630398264116,"user_tz":-120,"elapsed":52,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc","executionInfo":{"status":"ok","timestamp":1630398264117,"user_tz":-120,"elapsed":52,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = final_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W","executionInfo":{"status":"ok","timestamp":1630398264118,"user_tz":-120,"elapsed":53,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"status":"ok","timestamp":1630398264120,"user_tz":-120,"elapsed":54,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"35344d56-eef4-4491-c886-fdb1103ea053"},"source":["my_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['Technology (\"science of craft\", from Greek τ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Systems (e</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>g</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>machines) generating technology by taking an ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The prehistoric invention of shaped stone tool...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  correct_label  label\n","0  ['Technology (\"science of craft\", from Greek τ...              0      0\n","2                                         Systems (e              0      0\n","3                                                  g              0      0\n","4   machines) generating technology by taking an ...              0      1\n","6  The prehistoric invention of shaped stone tool...              0      0"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398264121,"user_tz":-120,"elapsed":53,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"525c5bdf-40d5-49a4-ffe8-480a96a580b2"},"source":["my_submission.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(252, 3)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398264124,"user_tz":-120,"elapsed":52,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"6b76332c-1fd1-4b5d-a1ce-42e0a0bcfc87"},"source":["test_df.label.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    252\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n","executionInfo":{"status":"ok","timestamp":1630398264125,"user_tz":-120,"elapsed":49,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==1)]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630398264127,"user_tz":-120,"elapsed":50,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"2edd76f4-df6d-4a51-86d5-6ab6d760cd50"},"source":["final.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11, 3)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7","executionInfo":{"status":"ok","timestamp":1630398264132,"user_tz":-120,"elapsed":50,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission.to_csv('stockholm/wikipedia_tech/verbs/wiki_xlm_sub.csv', index=False)"],"execution_count":38,"outputs":[]}]}