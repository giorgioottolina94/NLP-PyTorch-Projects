{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"wikipedia_adj_xlm.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QbOvSBgh_K2T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936209564,"user_tz":-120,"elapsed":233,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"41a7b52f-f95e-4e34-9332-4d1a5aa538bf"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vzqIeh0k_MbM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936212338,"user_tz":-120,"elapsed":2097,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"ff558f26-c3d1-4c22-c301-075ceabdd8c8"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Og8o_HG_Mf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936212699,"user_tz":-120,"elapsed":366,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"56d349b9-db8c-4f4d-b9bc-00a1b70e4232"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8uCANj-7fD_L","executionInfo":{"status":"ok","timestamp":1629936212700,"user_tz":-120,"elapsed":9,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JI3V3_oy_Mlp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936215960,"user_tz":-120,"elapsed":3268,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"77c48a7c-aebc-4a98-a852-2a06446c81e6"},"source":["!pip install transformers==3"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MspPBjFecRHv"},"source":["#Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gn-qmxXFkvG","executionInfo":{"status":"ok","timestamp":1629936215961,"user_tz":-120,"elapsed":23,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"7da25863-2270-4c90-a2ba-3f0d6e81d54c"},"source":["cd drive/My Drive/Colab Notebooks/experiments"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/experiments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ekbV40xzFsDB","executionInfo":{"status":"ok","timestamp":1629936216322,"user_tz":-120,"elapsed":380,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Use a subset for quick experiments\n","#data = data[:10000]\n","\n","from sklearn.model_selection import train_test_split as tts\n","import pandas as pd\n","data = pd.read_csv(\"stockholm/wikipedia_tech/adj/wiki_tech_labels_500.csv\")\n","data = data.rename(columns={'prediction': 'label'})\n","\n","# Split to train, val and test\n","train, test_df = tts(data[[\"sentence\", \"label\"]], random_state=42, test_size=0.1)\n","train, val = tts(train, random_state=42, test_size=test_df.shape[0])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sT3SnDiB_MoJ","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1629936216325,"user_tz":-120,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"3a2fad13-7ab6-4c3f-cf67-6643cb855b54"},"source":["import pandas as pd\n","# import pytreebank\n","\n","#cd drive/My Drive/Colab Notebooks/experiments/data\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"stockholm/wikipedia_tech/adj/wiki_tech_labels_500.csv\")\n","df = df.rename(columns={'prediction': 'label'})\n","# Report the number of sentences.\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of training sentences: 499\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['Technology (\"science of craft\", from Greek τ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Technology can be the knowledge of techniques...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Systems (e</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>g</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>machines) applying technology by taking an in...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  label\n","0  ['Technology (\"science of craft\", from Greek τ...      0\n","1   Technology can be the knowledge of techniques...      1\n","2                                         Systems (e      0\n","3                                                  g      0\n","4   machines) applying technology by taking an in...      0"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"BQGRN8y2_Mq1","executionInfo":{"status":"ok","timestamp":1629936216334,"user_tz":-120,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["#if label was not numeric\n","#from sklearn.preprocessing import LabelEncoder\n","\n","#encoder = LabelEncoder()\n","#df.label = encoder.fit_transform(df.label)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jdw6bWex_MuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936216335,"user_tz":-120,"elapsed":25,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"60c41b6f-a1de-4fb0-a33d-0850938a0b8f"},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values.astype(str)\n","labels = df.label.values\n","labels"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n","       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n","       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n","       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n","       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n","       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n","       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n","       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Gkx8ObbNcTUZ"},"source":["#Tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd_lJqo3cncS","executionInfo":{"status":"ok","timestamp":1629936219255,"user_tz":-120,"elapsed":2941,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9231afb4-a86c-4bb7-dd11-e36275a4ce8a"},"source":["!pip install sentencepiece"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uz-SE4L_MxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936220617,"user_tz":-120,"elapsed":1367,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a34acbf7-e269-4764-9db4-271cf6511337"},"source":["from transformers import XLMRobertaTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading XLMRobertaTokenizer ...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Loading XLMRobertaTokenizer ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zvi2HDlx_M0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936220619,"user_tz":-120,"elapsed":22,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"3b359325-bc9c-45e7-fa7f-21415e8cb5c6"},"source":["# Print the original sentence.\n","print('Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Original:  ['Technology (\"science of craft\", from Greek τέχνη, techne, \"art, skill, cunning of hand\"; and -λογία, -logia) is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation\n","Tokenized:  ['▁[', \"'\", 'tech', 'n', 'ology', '▁(\"', 'science', '▁of', '▁craft', '\",', '▁from', '▁gre', 'ek', '▁', 'τέ', 'χ', 'νη', ',', '▁tech', 'ne', ',', '▁\"', 'art', ',', '▁skill', ',', '▁cun', 'ning', '▁of', '▁hand', '\";', '▁and', '▁-', 'λογ', 'ία', ',', '▁-', 'logia', ')', '▁is', '▁the', '▁sum', '▁of', '▁techniques', ',', '▁skills', ',', '▁methods', ',', '▁and', '▁process', 'es', '▁used', '▁in', '▁the', '▁production', '▁of', '▁good', 's', '▁or', '▁services', '▁or', '▁in', '▁the', '▁accomplish', 'ment', '▁of', '▁objective', 's', ',', '▁such', '▁as', '▁scientific', '▁investigation']\n","Token IDs:  [378, 25, 20489, 19, 25443, 24073, 175201, 111, 131346, 830, 1295, 3514, 343, 6, 16012, 2088, 9417, 4, 51216, 86, 4, 44, 3960, 4, 112419, 4, 19466, 592, 111, 3535, 56128, 136, 20, 25892, 3420, 4, 20, 81331, 16, 83, 70, 10554, 111, 53088, 4, 59376, 4, 150624, 4, 136, 9433, 90, 11814, 23, 70, 36049, 111, 4127, 7, 707, 11374, 707, 23, 70, 163846, 674, 111, 151814, 7, 4, 6044, 237, 57456, 145456]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tdH-JjAyev73"},"source":["#Tokenize Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvQC4TbTcveP","executionInfo":{"status":"ok","timestamp":1629936220988,"user_tz":-120,"elapsed":381,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c93c6962-6809-4989-a1e5-bf0f92355bd9"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,          # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('labels:', labels)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Original:  ['Technology (\"science of craft\", from Greek τέχνη, techne, \"art, skill, cunning of hand\"; and -λογία, -logia) is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation\n","Token IDs: tensor([     0,    378,     25,  20489,     19,  25443,  24073, 175201,    111,\n","        131346,    830,   1295,   3514,    343,      6,  16012,   2088,   9417,\n","             4,  51216,     86,      4,     44,   3960,      4, 112419,      4,\n","         19466,    592,    111,   3535,  56128,    136,     20,  25892,   3420,\n","             4,     20,  81331,     16,     83,     70,  10554,    111,  53088,\n","             4,  59376,      4, 150624,      4,    136,   9433,     90,  11814,\n","            23,     70,  36049,    111,   4127,      7,    707,  11374,    707,\n","            23,     70, 163846,    674,    111, 151814,      7,      4,   6044,\n","           237,  57456, 145456,      2,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1,      1,      1,      1,      1,      1,      1,      1,\n","             1,      1])\n","labels: tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n","        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n","        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n","        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n","        1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dgHZenrtf4uH"},"source":["#Train and validation split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfrqA7YHcviX","executionInfo":{"status":"ok","timestamp":1629936220989,"user_tz":-120,"elapsed":13,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a4b16fb8-7304-491c-8e62-26efda013971"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["  449 training samples\n","   50 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ew-crkiKcvmk","executionInfo":{"status":"ok","timestamp":1629936220990,"user_tz":-120,"elapsed":7,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31XYmBgGgLMq"},"source":["#Train the model - XLMRobertaForSequenceClassification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCwrwWq3gKVJ","executionInfo":{"status":"ok","timestamp":1629936236885,"user_tz":-120,"elapsed":15902,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"de778695-8794-4721-fb5f-3620e3f3d170"},"source":["from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification - pretrained BERT model with a single linear classification layer on top. \n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMSwxx0gcvqh","executionInfo":{"status":"ok","timestamp":1629936236887,"user_tz":-120,"elapsed":48,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e2fd7a34-3754-4cdf-f1f4-20c138eb6d30"},"source":["params = list(model.named_parameters())\n","\n","print('The XLMRoberta model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["The XLMRoberta model has 203 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","roberta.embeddings.word_embeddings.weight               (250002, 768)\n","roberta.embeddings.position_embeddings.weight             (514, 768)\n","roberta.embeddings.token_type_embeddings.weight             (1, 768)\n","roberta.embeddings.LayerNorm.weight                           (768,)\n","roberta.embeddings.LayerNorm.bias                             (768,)\n","\n","==== First Transformer ====\n","\n","roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.query.bias             (768,)\n","roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n","roberta.encoder.layer.0.attention.self.key.bias               (768,)\n","roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n","roberta.encoder.layer.0.attention.self.value.bias             (768,)\n","roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n","roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n","roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n","roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n","roberta.encoder.layer.0.output.dense.bias                     (768,)\n","roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n","roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n","\n","==== Output Layer ====\n","\n","classifier.dense.weight                                   (768, 768)\n","classifier.dense.bias                                         (768,)\n","classifier.out_proj.weight                                  (2, 768)\n","classifier.out_proj.bias                                        (2,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"51Pe3nq8g3wB"},"source":["#Optimizer and Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"xWkNQFlVcvup","executionInfo":{"status":"ok","timestamp":1629936236889,"user_tz":-120,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) - \"W\" stands for weight decay fix\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtGiVJvNhALg","executionInfo":{"status":"ok","timestamp":1629936236890,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3a_KwCxhIw4"},"source":["#Train our model"]},{"cell_type":"code","metadata":{"id":"qZsMe3FshAPv","executionInfo":{"status":"ok","timestamp":1629936236890,"user_tz":-120,"elapsed":32,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIoz0srmhAZR","executionInfo":{"status":"ok","timestamp":1629936236893,"user_tz":-120,"elapsed":34,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf5f0hyehAhP","executionInfo":{"status":"ok","timestamp":1629936298420,"user_tz":-120,"elapsed":61560,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"9cc32b99-3c79-43cf-a1b1-65e6cc7e4600"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        print(b_input_ids.shape)\n","        print(b_input_mask.shape)\n","        print(b_labels.shape)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.69\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.82\n","  Validation Loss: 0.66\n","  Validation took: 0:00:00\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.58\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.59\n","  Validation took: 0:00:00\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.44\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.59\n","  Validation took: 0:00:00\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.31\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.60\n","  Validation took: 0:00:00\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.20\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.71\n","  Validation took: 0:00:00\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.14\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.76\n","  Validation took: 0:00:00\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.11\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation Loss: 0.79\n","  Validation took: 0:00:00\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.86\n","  Validation took: 0:00:00\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.91\n","  Validation took: 0:00:00\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([32, 128])\n","torch.Size([32, 128])\n","torch.Size([32])\n","torch.Size([1, 128])\n","torch.Size([1, 128])\n","torch.Size([1])\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:00:06\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation Loss: 0.93\n","  Validation took: 0:00:00\n","\n","Training complete!\n","Total training took 0:01:01 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"LHx9Nzi9hAn_","executionInfo":{"status":"ok","timestamp":1629936298423,"user_tz":-120,"elapsed":33,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"5fc645bf-641a-4241-9fe3-09e0024a03db"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.69</td>\n","      <td>0.66</td>\n","      <td>0.82</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.58</td>\n","      <td>0.59</td>\n","      <td>0.74</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.44</td>\n","      <td>0.59</td>\n","      <td>0.75</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.31</td>\n","      <td>0.60</td>\n","      <td>0.75</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.20</td>\n","      <td>0.71</td>\n","      <td>0.77</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.14</td>\n","      <td>0.76</td>\n","      <td>0.74</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.11</td>\n","      <td>0.79</td>\n","      <td>0.78</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.07</td>\n","      <td>0.86</td>\n","      <td>0.77</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.04</td>\n","      <td>0.91</td>\n","      <td>0.76</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.04</td>\n","      <td>0.93</td>\n","      <td>0.78</td>\n","      <td>0:00:06</td>\n","      <td>0:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.69         0.66           0.82       0:00:06         0:00:00\n","2               0.58         0.59           0.74       0:00:06         0:00:00\n","3               0.44         0.59           0.75       0:00:06         0:00:00\n","4               0.31         0.60           0.75       0:00:06         0:00:00\n","5               0.20         0.71           0.77       0:00:06         0:00:00\n","6               0.14         0.76           0.74       0:00:06         0:00:00\n","7               0.11         0.79           0.78       0:00:06         0:00:00\n","8               0.07         0.86           0.77       0:00:06         0:00:00\n","9               0.04         0.91           0.76       0:00:06         0:00:00\n","10              0.04         0.93           0.78       0:00:06         0:00:00"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"d9EJhSWFhAxL","executionInfo":{"status":"ok","timestamp":1629936299073,"user_tz":-120,"elapsed":673,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"e2aecd7a-7e8e-4444-fbf9-9c86cc5cd7d7"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"IT4-LcM-iPn8"},"source":["#Performance on test set"]},{"cell_type":"code","metadata":{"id":"8VipplfqhBhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936299080,"user_tz":-120,"elapsed":27,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"c788eefe-eb4a-4696-a364-18d34c8f998b"},"source":["import pandas as pd\n","\n","# # Load the dataset into a pandas dataframe.\n","test_df = pd.read_csv(\"stockholm/wikipedia_tech/adj/wiki_tech_adj_replaced_500.csv\")\n","test_df = test_df[test_df[\"prediction\"] == 0]\n","test_df = test_df.rename(columns={'prediction': 'label'})\n","\n","# # Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n","\n","# # Create sentence and label lists\n","sentences = test_df.sentence.values.astype(str)\n","labels = test_df.label.values\n","\n","# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# # For every sentence...\n","for sent in sentences:\n","#     # `encode_plus` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     #   (5) Pad or truncate the sentence to `max_length`\n","#     #   (6) Create attention masks for [PAD] tokens.\n","     encoded_dict = tokenizer.encode_plus(\n","                         sent,                      # Sentence to encode.\n","                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                         max_length = 64,           # Pad & truncate all sentences.\n","                         pad_to_max_length = True,\n","                         return_attention_mask = True,   # Construct attn. masks.\n","                         return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","    \n","#     # Add the encoded sentence to the list.    \n","     input_ids.append(encoded_dict['input_ids'])\n","    \n","#     # And its attention mask (simply differentiates padding from non-padding).\n","     attention_masks.append(encoded_dict['attention_mask'])\n","\n","# # Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# # Set the batch size.  \n","batch_size = 32  \n","\n","# # Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Number of test sentences: 499\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HLjiQA_TiUbi"},"source":["#Evaluation on test set"]},{"cell_type":"code","metadata":{"id":"Gnv1WjdwhBrg","executionInfo":{"status":"ok","timestamp":1629936299083,"user_tz":-120,"elapsed":26,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["# # Prediction on test set\n","\n","# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# # Put model in evaluation mode\n","# model.eval()\n","\n","# # Tracking variables \n","# predictions , true_labels = [], []\n","\n","# # Predict \n","# for batch in prediction_dataloader:\n","#   # Add batch to GPU\n","#   batch = tuple(t.to(device) for t in batch)\n","  \n","#   # Unpack the inputs from our dataloader\n","#   b_input_ids, b_input_mask, b_labels = batch\n","  \n","#   # Telling the model not to compute or store gradients, saving memory and \n","#   # speeding up prediction\n","#   with torch.no_grad():\n","#       # Forward pass, calculate logit predictions\n","#       outputs = model(b_input_ids, token_type_ids=None, \n","#                       attention_mask=b_input_mask)\n","\n","#   logits = outputs[0]\n","\n","#   # Move logits and labels to CPU\n","#   logits = logits.detach().cpu().numpy()\n","#   label_ids = b_labels.to('cpu').numpy()\n","  \n","#   # Store predictions and true labels\n","#   predictions.append(logits)\n","#   true_labels.append(label_ids)\n","\n","\n","# print('    DONE.')\n","# print('    predictions:::',predictions)\n","# print('    true_labels:::',true_labels)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qmj7fm818zxM","executionInfo":{"status":"ok","timestamp":1629936299606,"user_tz":-120,"elapsed":548,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfsjU8Upt38K","executionInfo":{"status":"ok","timestamp":1629936299608,"user_tz":-120,"elapsed":73,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission = pd.DataFrame()\n","my_submission['sentence'] = test_df['sentence']\n","my_submission['correct_label'] = test_df['label']\n","#my_submission['polarity'] = test_df['polarity']\n","#my_submission['intensity'] = test_df['intensity']\n","#my_submission['source_concept'] = test_df['source_concept']\n","#my_submission['target_concept'] = test_df['target_concept']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNV-BxYnuNZh","executionInfo":{"status":"ok","timestamp":1629936299614,"user_tz":-120,"elapsed":79,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final_preds = []\n","for p in predictions:\n","    for i in p:\n","        final_preds.append(np.argmax(i))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN1eyJlFuPCc","executionInfo":{"status":"ok","timestamp":1629936299616,"user_tz":-120,"elapsed":80,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = final_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDLPomjZuR7W","executionInfo":{"status":"ok","timestamp":1629936299618,"user_tz":-120,"elapsed":82,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission['label'] = my_submission['label'].map({0:0, 1:1})"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fqo58IR-ufCG","colab":{"base_uri":"https://localhost:8080/","height":205},"executionInfo":{"status":"ok","timestamp":1629936299622,"user_tz":-120,"elapsed":84,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"8affb592-ddad-47c7-d06c-1a3bad4d9b5b"},"source":["my_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>correct_label</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['Technology (\"science of craft\", from Greek τ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Systems (e</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>g</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>machines) applying technology by taking an in...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The sudden invention of shaped stone tools fol...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  correct_label  label\n","0  ['Technology (\"science of craft\", from Greek τ...              0      0\n","2                                         Systems (e              0      0\n","3                                                  g              0      0\n","4   machines) applying technology by taking an in...              0      0\n","6  The sudden invention of shaped stone tools fol...              0      0"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"YQs-dWrUw7XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936299623,"user_tz":-120,"elapsed":82,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"a89a3bb3-72ec-4d95-94f2-14af20bcb23d"},"source":["my_submission.shape"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(252, 3)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KsIV4fzxxttP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936299625,"user_tz":-120,"elapsed":69,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"52d607f8-f7df-450e-88e0-5241a77af2c2"},"source":["test_df.label.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    252\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"1BoXX0koxO6n","executionInfo":{"status":"ok","timestamp":1629936299628,"user_tz":-120,"elapsed":57,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["final = my_submission[(my_submission['correct_label'] == 0) & (my_submission['label'] ==1)]"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQGkR9dDxeSg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629936299630,"user_tz":-120,"elapsed":58,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}},"outputId":"16c763e8-6df5-46f5-e434-2042bbdc61e0"},"source":["final.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 3)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"g7YGsSh_uhz7","executionInfo":{"status":"ok","timestamp":1629936299631,"user_tz":-120,"elapsed":56,"user":{"displayName":"Giorgio Ottolina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiHqc78Tp0LGpgqAFdZiknA8pFcmI4JwnryQM6I=s64","userId":"08747627632687137907"}}},"source":["my_submission.to_csv('stockholm/wikipedia_tech/wiki_xlm_sub.csv', index=False)"],"execution_count":38,"outputs":[]}]}